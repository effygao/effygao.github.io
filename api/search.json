[{"id":"71ccfa0a8479931c66dcff584c51ed03","title":"计算机组成原理笔记","content":"CPU性能响应时间：指的就是，我们执行一个程序，到底需要花多少时间。花的时间越少，自然性能就越好。\n吞吐率：在一定的时间范围内，到底能处理多少事情。这里的“事情”，在计算机里就是处理的数据或者执行的程序指令。\n我们一般把性能，定义成响应时间的倒数，也就是：\n性能 &#x3D; 1&#x2F;响应时间\n\n程序运行的时间程序运行的时间&#x3D;程序运行结束的时间-程序开始运行的时间\n\n但是，计算机可能同时运行着好多个程序，CPU实际上不停地在各个程序之间进行切换。在这些走掉的时间里面，很可能CPU切换去运行别的程序了。所以这个时间并不准。\n我们使用time命令统计运行时间：\n$ time seq\n  1000000 | wc -l \n1000000 \nreal 0m0.101s \nuser 0m0.031s \nsys  0m0.016s\n\n其中real就是Wall Clock Time，而程序实际花费的CPU执行时间，就是user time加上sys time。\n我们下面对程序的CPU执行时间进行拆解：\n程序的CPU执行时间&#x3D;CPU时钟周期数×时钟周期时间\n\n时钟周期时间：如果一台电脑的主频是2.8GHz，那么可以简单认为，CPU在1秒时间内，可以执行的简单指令的数量是2.8G条。在这个2.8GHz的CPU上，这个时钟周期时间，就是1&#x2F;2.8G。\n对于上面的公式：CPU时钟周期数还可以拆解成指令数×每条指令的平均时钟周期数Cycles Per Instruction，简称CPI）。\n程序的CPU执行时间&#x3D;指令数×CPI×Clock Cycle Time\n\n并行优化由于通过提升CPU频率已经达到瓶颈，所以开始推出多核CPU，通过提升“吞吐率”而不是“响应时间”，来达到目的。\n但是，并不是所有问题，都可以通过并行提高性能来解决。如果想要使用这种思想，需要满足这样几个条件。\n1、需要进行的计算，本身可以分解成几个可以并行的任务。2、需要能够分解好问题，并确保几个人的结果能够汇总到一起。3、在“汇总”这个阶段，是没有办法并行进行的，还是得顺序执行，一步一步来。\n所以并行计算涉及到了一个阿姆达尔定律（Amdahl’s Law）。\n对于一个程序进行优化之后，处理器并行运算之后效率提升的情况。具体可以用这样一个公式来表示：\n优化后的执行时间 &#x3D; 受优化影响的执行时间&#x2F;加速倍数+不受影响的执行时间\n比如做一段数据的计算， 本来如果整个计算单核完成需要120ns，但是我们可以将这个任务拆分成4个，最后再汇总加起来。\n如果每个任务单独计算需要25ns，加起来汇总需要20ns，那么4个任务并行计算需要100&#x2F;4+20&#x3D;25ns。\n即使我们增加更多的并行度来提供加速倍数，比如有100个CPU，整个时间也需要100&#x2F;100+20&#x3D;21ns。\n\n从编译到汇编，代码怎么变成机器码？如下C语言程序例子：\n&#x2F;&#x2F; test.cint main()&#123;\n  int a &#x3D; 1;\n  int b &#x3D; 2;\n  a &#x3D; a + b;\n&#125;\n我们给两个变量 a、b分别赋值1、2，然后再将a、b两个变量中的值加在一起，重新赋值给了a整个变量。\n要让这段程序在一个Linux操作系统上跑起来，我们需要把整个程序翻译成一个汇编语言（ASM，Assembly Language）的程序，这个过程我们一般叫编译（Compile）成汇编代码。\n针对汇编代码，我们可以再用汇编器（Assembler）翻译成机器码（Machine Code）。这些机器码由“0”和“1”组成的机器语言表示。这一条条机器码，就是一条条的计算机指令。这样一串串的16进制数字，就是我们CPU能够真正认识的计算机指令。\n\n汇编代码其实就是“给程序员看的机器码”，也正因为这样，机器码和汇编代码是一一对应的。我们人类很容易记住add、mov这些用英文表示的指令，而8b 45 f8这样的指令，由于很难一下子看明白是在干什么，所以会非常难以记忆。所以我们需要汇编代码。\n指令是如何被执行的一个CPU里面会有很多种不同功能的寄存器。我这里给你介绍三种比较特殊的。\n1、PC寄存器（Program Counter Register），也叫指令地址寄存器（Instruction Address Register）。它就是用来存放下一条需要执行的计算机指令的内存地址。\n2、指令寄存器（Instruction Register），用来存放当前正在执行的指令。\n3、条件码寄存器（Status Register），用里面的一个一个标记位（Flag），存放CPU进行算术或者逻辑计算的结果。\n\n实际上，一个程序执行的时候，CPU会根据PC寄存器里的地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。可以看到，一个程序的一条条指令，在内存里面是连续保存的，也会一条条顺序加载。\n程序的执行和跳转现在就来看一个包含if…else的简单程序。\n&#x2F;&#x2F; test.c\n#include &lt;time.h&gt;\n#include &lt;stdlib.h&gt; \nint main() &#123; \n    srand(time(NULL)); \n    int r &#x3D; rand() % 2; \n    int a &#x3D; 10; \n    if (r &#x3D;&#x3D; 0) &#123; \n        a &#x3D; 1; \n        &#125; else &#123; \n        a &#x3D; 2; \n&#125;\n\n把这个程序编译成汇编代码。\nif (r &#x3D;&#x3D; 0)\n3b: 83 7d fc 00     cmp DWORD PTR [rbp-0x4],0x0 \n3f: 75 09           jne 4a &lt;main+0x4a&gt;\n &#123;\n     a &#x3D; 1;\n41: c7 45 f8 01 00 00 00      mov DWORD PTR [rbp-0x8],0x1 \n48: eb 07                     jmp 51 &lt;main+0x51&gt;\n    &#125; \n    else \n    &#123;\n         a &#x3D; 2;\n4a: c7 45 f8 02 00 00 00   mov DWORD PTR [rbp-0x8],0x2\n51: b8 00 00 00 00         mov eax,0x0\n&#125;\n\n可以看到，这里对于r &#x3D;&#x3D; 0的条件判断，被编译成了cmp和jne这两条指令。\n对于：\ncmp DWORD PTR [rbp-0x4],0x0\ncmp指令比较了前后两个操作数的值，这里的DWORD PTR代表操作的数据类型是32位的整数，而[rbp-0x4]则是一个寄存器的地址。所以，第一个操作数就是从寄存器里拿到的变量r的值。第二个操作数0x0就是我们设定的常量0的16进制表示。cmp指令的比较结果，会存入到条件码寄存器当中去。\n在这里，如果比较的结果是False，也就是0，就把零标志条件码（对应的条件码是ZF，Zero Flag）设置为1。\ncmp指令执行完成之后，PC寄存器会自动自增，开始执行下一条jne的指令。\n对于：\njne 4a &lt;main+0x4a&gt;\njne指令，是jump if not equal的意思，它会查看对应的零标志位。如果为0，会跳转到后面跟着的操作数4a的位置。这个4a，对应这里汇编代码的行号，也就是上面设置的else条件里的第一条指令。\n当跳转发生的时候，PC寄存器就不再是自增变成下一条指令的地址，而是被直接设置成这里的4a这个地址。这个时候，CPU再把4a地址里的指令加载到指令寄存器中来执行。\n4a: c7 45 f8 02 00 00 00     mov DWORD PTR [rbp-0x8],0x2 \n51: b8 00 00 00 00           mov eax,0x0\n\n4a的指令，实际是一条mov指令，第一个操作数和前面的cmp指令一样，是另一个32位整型的寄存器地址，以及对应的2的16进制值0x2。mov指令把2设置到对应的寄存器里去，相当于一个赋值操作。然后，PC寄存器里的值继续自增，执行下一条mov指令。\n下一条指令也是mov，第一个操作数eax，代表累加寄存器，第二个操作数0x0则是16进制的0的表示。这条指令其实没有实际的作用，它的作用是一个占位符。\n函数调用我们先来看个例子：\n&#x2F;&#x2F; function_example.c \n#include &lt;stdio.h&gt; \nint static add(int a, int b) &#123;\n return a+b; \n&#125; \nint main() \n&#123; \nint x &#x3D; 5; \nint y &#x3D; 10; \nint u &#x3D; add(x, y);\n&#125;\n我们把这个程序编译之后：\nint static add(int a, int b) \n&#123;\n 0: 55 push rbp \n1: 48 89 e5 mov rbp,rsp \n4: 89 7d fc mov DWORD PTR [rbp-0x4],edi \n7: 89 75 f8 mov DWORD PTR [rbp-0x8],esi \nreturn a+b; \na: 8b 55 fc mov edx,DWORD PTR [rbp-0x4] \nd: 8b 45 f8 mov eax,DWORD PTR [rbp-0x8] \n10:  5d pop rbp \n13: c3 ret 0000000000000014 &lt;main&gt;:\n int main() \n&#123; \n14: 55 push rbp \n15: 48 89 e5 mov rbp,rsp \n18: 48 83 ec 10 sub rsp,0x10 \n    int x &#x3D; 5; \n1c: c7 45 fc 05 00 00 00 mov DWORD PTR [rbp-0x4],0x5 \n    int y &#x3D; 10; \n23: c7 45 f8 0a 00 00 00 mov DWORD PTR [rbp-0x8],0xa \n    int u &#x3D; add(x, y); \n2a: 8b 55 f8 mov edx,DWORD PTR [rbp-0x8] \n2d: 8b 45 fc mov eax,DWORD PTR [rbp-0x4] 30: 89 d6 mov esi,edx \n32: 89 c7 mov edi,eax 34: e8 c7 ff ff ff call 0 &lt;add&gt; \n39: 89 45 f4 mov DWORD PTR [rbp-0xc],eax \n3c: b8 00 00 00 00 mov eax,0x0 \n&#125; \n41: c9 leave \n42: c3 ret01 d0 add eax,edx \n&#125; \n12:\n在add函数编译之后，代码先执行了一条push指令和一条mov指令；在函数执行结束的时候，又执行了一条pop和一条ret指令。\nadd函数的第0行，push rbp这个指令，就是在进行压栈。这里的rbp又叫栈帧指针（Frame Pointer），是一个存放了当前栈帧位置的寄存器。push rbp就把之前调用函数的返回地址，压到栈顶。\n接着，第1行的一条命令mov rbp, rsp里，则是把rsp这个栈指针（Stack Pointer）的值复制到rbp里，而rsp始终会指向栈顶。这个命令意味着，rbp这个栈帧指针指向的返回地址，变成当前最新的栈顶，也就是add函数的返回地址了。\n而在函数add执行完成之后，又会分别调用第12行的pop rbp来将当前的栈顶出栈，然后调用第13行的ret指令，将程序的控制权返回到出栈后的栈顶，也就是main函数的返回地址。\n拆解程序执行实际上，“C语言代码-汇编代码-机器码” 这个过程，在我们的计算机上进行的时候是由两部分组成的。\n第一个部分由编译（Compile）、汇编（Assemble）以及链接（Link）三个阶段组成。在这三个阶段完成之后，我们就生成了一个可执行文件。\n第二部分，我们通过装载器（Loader）把可执行文件装载（Load）到内存中。CPU从内存中读取指令和数据，来开始真正执行程序。\n\n静态链接程序的链接，是把对应的不同文件内的代码段，合并到一起，成为最后的可执行文件。\n在可执行文件里，我们可以看到，对应的函数名称，像add、main等等，乃至你自己定义的全局可以访问的变量名称对应的地址，存储在一个叫作符号表（Symbols Table）的位置里。符号表相当于一个地址簿，把名字和地址关联了起来。\n经过程序的链接之后，main函数里调用add的跳转地址，不再是下一条指令的地址了，而是add函数的入口地址了。\n链接器会扫描所有输入的目标文件，然后把所有符号表里的信息收集起来，构成一个全局的符号表。然后再根据重定位表，把所有不确定要跳转地址的代码，根据符号表里面存储的地址，进行一次修正。最后，把所有的目标文件的对应段进行一次合并，变成了最终的可执行代码。\n这个合并代码段的方法，是叫静态链接。\n动态链接在动态链接的过程中，我们想要“链接”的，不是存储在硬盘上的目标文件代码，而是加载到内存中的共享库（Shared Libraries）。\n要想要在程序运行的时候共享代码，也有一定的要求，就是这些机器码必须是“地址无关”的。换句话说就是，这段代码，无论加载在哪个内存地址，都能够正常执行。\n\n动态代码库内部的变量和函数调用都是使用相对地址。因为整个共享库是放在一段连续的虚拟内存地址中的，无论装载到哪一段地址，不同指令之间的相对地址都是不变的。\n装载程序在运行这些可执行文件的时候，我们其实是通过一个装载器，解析ELF或者PE格式的可执行文件。装载器会把对应的指令和数据加载到内存里面来，让CPU去执行。\n装载器需要满足两个要求：\n1、可执行程序加载后占用的内存空间应该是连续的。因为CPU在执行指令的时候，程序计数器是顺序地一条一条指令执行下去。\n2、我们需要同时加载很多个程序，并且不能让程序自己规定在内存中加载的位置。因为我们现在的计算机通常会同时运行很多个程序，可能你想要的内存地址已经被其他加载了的程序占用了。\n基于上面，我们需要在内存空间地址和整个程序指令指定的内存地址做一个映射。\n把指令里用到的内存地址叫作虚拟内存地址（Virtual Memory Address），实际在内存硬件里面的空间地址，我们叫物理内存地址（Physical Memory Address）。\n内存分页分页是把整个物理内存空间切成一段段固定尺寸的大小。而对应的程序所需要占用的虚拟内存空间，也会同样切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。\n从虚拟内存到物理内存的映射，不再是拿整段连续的内存的物理地址，而是按照一个一个页来的。\n\n分页之后避免了整个程序和硬盘进行交换而产生性能瓶颈。即使内存空间不够，需要让现有的、正在运行的其他程序，通过内存交换释放出一些内存的页出来，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，让整个机器被内存交换的过程给卡住。\n浮点数和定点数我们先来看一个问题，在Chrome浏览器里面通过开发者工具，打开浏览器里的Console，在里面输入“0.3 + 0.6”：\n&gt;&gt;&gt; 0.3 + 0.6\n0.8999999999999999\n下面我们来一步步解释，为什么会这样。\n定点数如果我们用32个比特表示整数，用4个比特来表示0～9的整数，那么32个比特就可以表示8个这样的整数。\n然后我们把最右边的2个0～9的整数，当成小数部分；把左边6个0～9的整数，当成整数部分。这样，我们就可以用32个比特，来表示从0到999999.99这样1亿个实数了。\n这种用二进制来表示十进制的编码方式，叫作BCD编码。这种小数点固定在某一位的方式，我们也就把它称为定点数。\n缺点：\n第一，这样的表示方式有点“浪费”。本来32个比特我们可以表示40亿个不同的数，但是在BCD编码下，只能表示1亿个数。\n第二，这样的表示方式没办法同时表示很大的数字和很小的数字。\n浮点数我们在表示一个很大的数的时候，通常可以用科学计数法来表示。\n在计算机里，我也可以用科学计数法来表示实数。浮点数的科学计数法的表示，有一个IEEE的标准，它定义了两个基本的格式。一个是用32比特表示单精度的浮点数，也就是我们常常说的float或者float32类型。另外一个是用64比特表示双精度的浮点数，也就是我们平时说的double或者float64类型。\n单精度单精度的32个比特可以分成三部分。\n\n第一部分是一个符号位，用来表示是正数还是负数。我们一般用s来表示。在浮点数里，我们不像正数分符号数还是无符号数，所有的浮点数都是有符号的。\n接下来是一个8个比特组成的指数位。我们一般用e来表示。8个比特能够表示的整数空间，就是0～255。我们在这里用1～254映射到-126～127这254个有正有负的数上。\n最后，是一个23个比特组成的有效数位。我们用f来表示。综合科学计数法，我们的浮点数就可以表示成下面这样：$(-1)^s×1.f×2^e$\n特殊值的表示\n以0.5为例子。0.5的符号为s应该是0，f应该是0，而e应该是-1，也就是***$0.5&#x3D; (-1)^0×1.0×2^{-1}&#x3D;0.5$***，对应的浮点数表示，就是32个比特。\n不考虑符号的话，浮点数能够表示的最小的数和最大的数，差不多是***$1.17×10^{-38}$和$3.40×10^{38}$***。\n回到我们最开头，为什么我们用0.3 + 0.6不能得到0.9呢？这是因为，浮点数没有办法精确表示0.3、0.6和0.9。\n浮点数的二进制转化我们输入一个任意的十进制浮点数，背后都会对应一个二进制表示。\n比如：9.1，那么，首先，我们把这个数的整数部分，变成一个二进制。这里的9，换算之后就是1001。\n接着，我们把对应的小数部分也换算成二进制。和整数的二进制表示采用“除以2，然后看余数”的方式相比，小数部分转换成二进制是用一个相似的反方向操作，就是乘以2，然后看看是否超过1。如果超过1，我们就记下1，并把结果减去1，进一步循环操作。在这里，我们就会看到，0.1其实变成了一个无限循环的二进制小数，0.000110011。这里的“0011”会无限循环下去。\n\n结果就是：***$1.0010$$0011$$0011… × 2^3$***\n这里的符号位s &#x3D; 0，对应的有效位f&#x3D;001000110011…。因为f最长只有23位，那这里“0011”无限循环，最多到23位就截止了。于是，f&#x3D;00100011001100110011 001。最后的一个“0011”循环中的最后一个“1”会被截断掉。\n对应的指数为e，代表的应该是3。因为指数位有正又有负，所以指数位在127之前代表负数，之后代表正数，那3其实对应的是加上127的偏移量130，转化成二进制，就是130，对应的就是指数位的二进制，表示出来就是10000010。\n\n最终得到的二进制表示就变成了：\n010000010 0010 0011001100110011 001\n如果我们再把这个浮点数表示换算成十进制， 实际准确的值是9.09999942779541015625。\n浮点数的加法和精度损失浮点数的加法是：先对齐、再计算。\n那我们在计算0.5+0.125的浮点数运算的时候，首先要把两个的指数位对齐，也就是把指数位都统一成两个其中较大的-1。对应的有效位1.00…也要对应右移两位，因为f前面有一个默认的1，所以就会变成0.01。然后我们计算两者相加的有效位1.f，就变成了有效位1.01，而指数位是-1，这样就得到了我们想要的加法后的结果。\n\n其中指数位较小的数，需要在有效位进行右移，在右移的过程中，最右侧的有效位就被丢弃掉了。这会导致对应的指数位较小的数，在加法发生之前，就丢失精度。\n指令周期（Instruction Cycle）计算机每执行一条指令的过程，可以分解成这样几个步骤。\n\nFetch（取得指令），也就是从PC寄存器里找到对应的指令地址，根据指令地址从内存里把具体的指令，加载到指令寄存器中，然后把PC寄存器自增，好在未来执行下一条指令。\nDecode（指令译码），也就是根据指令寄存器里面的指令，解析成要进行什么样的操作，是R、I、J中的哪一种指令，具体要操作哪些寄存器、数据或者内存地址。\nExecute（执行指令），也就是实际运行对应的R、I、J这些特定的指令，进行算术逻辑操作、数据传输或者直接的地址跳转。\nFetch - Decode - Execute循环称之为指令周期（Instruction Cycle）。\n\n\n在取指令的阶段，我们的指令是放在存储器里的，实际上，通过PC寄存器和指令寄存器取出指令的过程，是由控制器（Control Unit）操作的。指令的解码过程，也是由控制器进行的。一旦到了执行指令阶段，无论是进行算术操作、逻辑操作的R型指令，还是进行数据传输、条件分支的I型指令，都是由算术逻辑单元（ALU）操作的，也就是由运算器处理的。不过，如果是一个简单的无条件地址跳转，那么我们可以直接在控制器里面完成，不需要用到运算器。\n\n时序逻辑电路有一些电路，只需要给定输入，就能得到固定的输出。这样的电路，我们称之为组合逻辑电路（Combinational Logic Circuit）。\n时序逻辑电路有以下几个特点：\n1、自动运行，时序电路接通之后可以不停地开启和关闭开关，进入一个自动运行的状态。\n2、存储。通过时序电路实现的触发器，能把计算结果存储在特定的电路里面，而不是像组合逻辑电路那样，一旦输入有任何改变，对应的输出也会改变。\n3、时序电路使得不同的事件按照时间顺序发生。\n最常见的就是D触发器，电路的输出信号不单单取决于当前的输入信号，还要取决于输出信号之前的状态。\nPC寄存器PC寄存器就是程序计数器。\n\n加法器的两个输入，一个始终设置成1，另外一个来自于一个D型触发器A。我们把加法器的输出结果，写到这个D型触发器A里面。于是，D型触发器里面的数据就会在固定的时钟信号为1的时候更新一次。\n这样，我们就有了一个每过一个时钟周期，就能固定自增1的自动计数器了。\n最简单的CPU流程\n1、首先，有一个自动计数器会随着时钟主频不断地自增，来作为我们的PC寄存器。\n2、在这个自动计数器的后面，我们连上一个译码器（用来寻址，将指令内存地址转换成指令）。译码器还要同时连着我们通过大量的D触发器组成的内存。\n3、自动计数器会随着时钟主频不断自增，从译码器当中，找到对应的计数器所表示的内存地址，然后读取出里面的CPU指令。\n4、读取出来的CPU指令会通过我们的CPU时钟的控制，写入到一个由D触发器组成的寄存器，也就是指令寄存器当中。\n5、在指令寄存器后面，我们可以再跟一个译码器。这个译码器不再是用来寻址的了，而是把我们拿到的指令，解析成opcode和对应的操作数。\n6、当我们拿到对应的opcode和操作数，对应的输出线路就要连接ALU，开始进行各种算术和逻辑运算。对应的计算结果，则会再写回到D触发器组成的寄存器或者内存当中。\n指令流水线指令流水线指的是把一个指令拆分成一个一个小步骤，从而来减少单条指令执行的“延时”。通过同时在执行多条指令的不同阶段，我们提升了CPU的“吞吐率”。\n如果我们把一个指令拆分成“取指令-指令译码-执行指令”这样三个部分，那这就是一个三级的流水线。如果我们进一步把“执行指令”拆分成“ALU计算（指令执行）-内存访问-数据写回”，那么它就会变成一个五级的流水线。\n五级的流水线，就表示我们在同一个时钟周期里面，同时运行五条指令的不同阶段。\n我们可以看这样一个例子。我们顺序执行这样三条指令。\n1、一条整数的加法，需要200ps。\n2、一条整数的乘法，需要300ps。\n3、一条浮点数的乘法，需要600ps\n如果我们是在单指令周期的CPU上运行，最复杂的指令是一条浮点数乘法，那就需要600ps。那这三条指令，都需要600ps。三条指令的执行时间，就需要1800ps。\n如果我们采用的是6级流水线CPU，每一个Pipeline的Stage都只需要100ps。那么，在这三个指令的执行过程中，在指令1的第一个100ps的Stage结束之后，第二条指令就开始执行了。在第二条指令的第一个100ps的Stage结束之后，第三条指令就开始执行了。这种情况下，这三条指令顺序执行所需要的总时间，就是800ps。那么在1800ps内，使用流水线的CPU比单指令周期的CPU就可以多执行一倍以上的指令数。\n\n流水线设计CPU的风险结构冒险\n可以看到，在第1条指令执行到访存（MEM）阶段的时候，流水线里的第4条指令，在执行取指令（Fetch）的操作。访存和取指令，都要进行内存数据的读取。但是内存在一个时钟周期是没办法都做的。\n解决办法：在高速缓存层面拆分成指令缓存和数据缓存\n在CPU内部的高速缓存部分进行了区分，把高速缓存分成了指令缓存（Instruction Cache）和数据缓存（Data Cache）两部分。\n\n数据冒险1、先写后读\nint main() \n&#123; int a &#x3D; 1;\n  int b &#x3D; 2;\n  a &#x3D; a + 2;\n  b &#x3D; a + 3; &#125;\n\n这里需要保证a和b的值先赋，然后才能进行准确的运算。这个先写后读的依赖关系，我们一般被称之为数据依赖，也就是Data Dependency。\n2、先读后写\nmain()&#123; int a &#x3D; 1;\n  int b &#x3D; 2;\n  a &#x3D; b + a; \n  b &#x3D; a + b; &#125;\n\n这里我们先要读出a &#x3D; b+a，然后才能正确的写入b的值。这个先读后写的依赖，一般被叫作反依赖，也就是Anti-Dependency。\n3、写后再写\nmain()&#123; int a &#x3D; 1;\n  a &#x3D; 2; &#125;\n很明显，两个写入操作不能乱，要不然最终结果就是错误的。这个写后再写的依赖，一般被叫作输出依赖，也就是Output Dependency。\n解决办法：流水线停顿（Pipeline Stall）\n\n如果我们发现了后面执行的指令，会对前面执行的指令有数据层面的依赖关系，那最简单的办法就是“再等等”。我们在进行指令译码的时候，会拿到对应指令所需要访问的寄存器和内存地址。\n在实践过程中，在执行后面的操作步骤前面，插入一个NOP操作，也就是执行一个其实什么都不干的操作。\n在执行的代码中，一旦遇到 if…else 这样的条件分支，或者 for&#x2F;while 循环的时候会发生类似cmp比较指令、jmp和jle这样的条件跳转指令。\n在jmp指令发生的时候，CPU可能会跳转去执行其他指令。jmp后的那一条指令是否应该顺序加载执行，在流水线里面进行取指令的时候，我们没法知道。要等jmp指令执行完成，去更新了PC寄存器之后，我们才能知道，是否执行下一条指令，还是跳转到另外一个内存地址，去取别的指令。\n解决办法： \n缩短分支延迟\n条件跳转指令其实进行了两种电路操作。\n第一种，是进行条件比较。\n第二种，是进行实际的跳转，也就是把要跳转的地址信息写入到PC寄存器。无论是opcode，还是对应的条件码寄存器，还是我们跳转的地址，都是在指令译码（ID）的阶段就能获得的。而对应的条件码比较的电路，只要是简单的逻辑门电路就可以了，并不需要一个完整而复杂的ALU。\n所以，我们可以将条件判断、地址跳转，都提前到指令译码阶段进行，而不需要放在指令执行阶段。对应的，我们也要在CPU里面设计对应的旁路，在指令译码阶段，就提供对应的判断比较的电路。\n分支预测\n最简单的分支预测技术，叫作“假装分支不发生”。顾名思义，自然就是仍然按照顺序，把指令往下执行。\n如果分支预测失败了呢？那我们就把后面已经取出指令已经执行的部分，给丢弃掉。这个丢弃的操作，在流水线里面，叫作Zap或者Flush。CPU不仅要执行后面的指令，对于这些已经在流水线里面执行到一半的指令，我们还需要做对应的清除操作。\n\n动态分支预测\n就是记录当前分支的比较情况，直接用当前分支的比较情况，来预测下一次分支时候的比较情况。\n例子：\nclass BranchPrediction &#123;    public static void main(String args[]) &#123;        \n        long start &#x3D; System.currentTimeMillis();\n        for (int i &#x3D; 0; i &lt; 100; i++) &#123;\n            for (int j &#x3D; 0; j &lt;1000; j ++) &#123;\n                for (int k &#x3D; 0; k &lt; 10000; k++) &#123;\n                &#125;\n            &#125;\n        &#125;\n        long end &#x3D; System.currentTimeMillis();\n        System.out.println(&quot;Time spent is &quot; + (end - start));\n                \n        start &#x3D; System.currentTimeMillis();\n        for (int i &#x3D; 0; i &lt; 10000; i++) &#123;\n            for (int j &#x3D; 0; j &lt;1000; j ++) &#123;\n                for (int k &#x3D; 0; k &lt; 100; k++) &#123;\n                &#125;\n            &#125;\n        &#125;\n        end &#x3D; System.currentTimeMillis();\n        System.out.println(&quot;Time spent is &quot; + (end - start) + &quot;ms&quot;);\n    &#125;\n&#125;\n\n输出：\nspent in first loop is 5msTime spent in second loop is 15ms\n\n\n分支预测策略最简单的一个方式，自然是“假定分支不发生”。对应到上面的循环代码，就是循环始终会进行下去。在这样的情况下，上面的第一段循环，也就是内层 k 循环10000次的代码。每隔10000次，才会发生一次预测上的错误。而这样的错误，在第二层 j 的循环发生的次数，是1000次。\n最外层的 i 的循环是100次。每个外层循环一次里面，都会发生1000次最内层 k 的循环的预测错误，所以一共会发生 100 × 1000 &#x3D; 10万次预测错误。\n操作数前推通过流水线停顿可以解决资源竞争产生的问题，但是，插入过多的NOP操作，意味着我们的CPU总是在空转，干吃饭不干活。所以我们提出了操作数前推这样的解决方案。\n1、  add $t0, $s2,$s1\n2、  add $s2, $s1,$t0\n第一条指令，把 s1 和 s2 寄存器里面的数据相加，存入到 t0 这个寄存器里面。\n第二条指令，把 s1 和 t0 寄存器里面的数据相加，存入到 s2 这个寄存器里面。\n\n我们要在第二条指令的译码阶段之后，插入对应的NOP指令，直到前一天指令的数据写回完成之后，才能继续执行。但是这样浪费了两个时钟周期。\n这个时候完全可以在第一条指令的执行阶段完成之后，直接将结果数据传输给到下一条指令的ALU。然后，下一条指令不需要再插入两个NOP阶段，就可以继续正常走到执行阶段。\n\n这样的解决方案，我们就叫作操作数前推（Operand Forwarding），或者操作数旁路（Operand Bypassing）。\nCPU指令乱序执行\n1、在取指令和指令译码的时候，乱序执行的CPU和其他使用流水线架构的CPU是一样的。它会一级一级顺序地进行取指令和指令译码的工作。\n2、在指令译码完成之后，CPU不会直接进行指令执行，而是进行一次指令分发，把指令发到一个叫作保留站（Reservation Stations）的地方。\n3、这些指令不会立刻执行，而要等待它们所依赖的数据，传递给它们之后才会执行。\n4、一旦指令依赖的数据来齐了，指令就可以交到后面的功能单元（Function Unit，FU），其实就是ALU，去执行了。我们有很多功能单元可以并行运行，但是不同的功能单元能够支持执行的指令并不相同。\n5、指令执行的阶段完成之后，我们并不能立刻把结果写回到寄存器里面去，而是把结果再存放到一个叫作重排序缓冲区（Re-Order Buffer，ROB）的地方。\n6、在重排序缓冲区里，我们的CPU会按照取指令的顺序，对指令的计算结果重新排序。只有排在前面的指令都已经完成了，才会提交指令，完成整个指令的运算结果。\n7、实际的指令的计算结果数据，并不是直接写到内存或者高速缓存里，而是先写入存储缓冲区（Store Buffer面，最终才会写入到高速缓存和内存里。\n8、在乱序执行的情况下，只有CPU内部指令的执行层面，可能是“乱序”的。\n例子：\na &#x3D; b + c\nd &#x3D; a * e\nx &#x3D; y * z\n\n里面的 d 依赖于 a 的计算结果，不会在 a 的计算完成之前执行。但是我们的CPU并不会闲着，因为 x &#x3D; y * z 的指令同样会被分发到保留站里。因为 x 所依赖的 y 和 z 的数据是准备好的， 这里的乘法运算不会等待计算 d，而会先去计算 x 的值。\n如果我们只有一个FU能够计算乘法，那么这个FU并不会因为 d 要等待 a 的计算结果，而被闲置，而是会先被拿去计算 x。\n在 x 计算完成之后，d 也等来了 a 的计算结果。这个时候，我们的FU就会去计算出 d 的结果。然后在重排序缓冲区里，把对应的计算结果的提交顺序，仍然设置成 a -&gt; d -&gt; x，而计算完成的顺序是 x -&gt; a -&gt; d。\n在这整个过程中，整个计算乘法的FU都没有闲置，这也意味着我们的CPU的吞吐率最大化了。\n乱序执行，极大地提高了CPU的运行效率。核心原因是，现代CPU的运行速度比访问主内存的速度要快很多。如果完全采用顺序执行的方式，很多时间都会浪费在前面指令等待获取内存数据的时间里。CPU不得不加入NOP操作进行空转。\n","slug":"computer-organization","date":"2022-07-05T07:02:41.000Z","categories_index":"","tags_index":"计组原、网络","author_index":"网工混子"}]
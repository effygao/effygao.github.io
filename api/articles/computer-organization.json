{"title":"计算机组成原理笔记","uid":"71ccfa0a8479931c66dcff584c51ed03","slug":"computer-organization","date":"2022-07-05T07:02:41.000Z","updated":"2022-07-05T11:23:15.564Z","comments":true,"path":"api/articles/computer-organization.json","keywords":null,"cover":[],"content":"<h4 id=\"CPU性能\"><a href=\"#CPU性能\" class=\"headerlink\" title=\"CPU性能\"></a>CPU性能</h4><p>响应时间：指的就是，我们执行一个程序，到底需要花多少时间。花的时间越少，自然性能就越好。</p>\n<p>吞吐率：在一定的时间范围内，到底能处理多少事情。这里的“事情”，在计算机里就是处理的数据或者执行的程序指令。</p>\n<p>我们一般把性能，定义成响应时间的倒数，也就是：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">性能 &#x3D; 1&#x2F;响应时间<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<h4 id=\"程序运行的时间\"><a href=\"#程序运行的时间\" class=\"headerlink\" title=\"程序运行的时间\"></a>程序运行的时间</h4><pre class=\"line-numbers language-none\"><code class=\"language-none\">程序运行的时间&#x3D;程序运行结束的时间-程序开始运行的时间<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<p>但是，计算机可能同时运行着好多个程序，CPU实际上不停地在各个程序之间进行切换。在这些走掉的时间里面，很可能CPU切换去运行别的程序了。所以这个时间并不准。</p>\n<p>我们使用time命令统计运行时间：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">$ time seq\n  1000000 | wc -l \n1000000 \nreal 0m0.101s \nuser 0m0.031s \nsys  0m0.016s<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>其中real就是Wall Clock Time，而程序实际花费的CPU执行时间，就是user time加上sys time。</p>\n<p>我们下面对程序的CPU执行时间进行拆解：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">程序的CPU执行时间&#x3D;CPU时钟周期数×时钟周期时间<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<p>时钟周期时间：如果一台电脑的主频是2.8GHz，那么可以简单认为，CPU在1秒时间内，可以执行的简单指令的数量是2.8G条。在这个2.8GHz的CPU上，这个时钟周期时间，就是1&#x2F;2.8G。</p>\n<p>对于上面的公式：CPU时钟周期数还可以拆解成指令数×每条指令的平均时钟周期数Cycles Per Instruction，简称CPI）。</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">程序的CPU执行时间&#x3D;指令数×CPI×Clock Cycle Time<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<h4 id=\"并行优化\"><a href=\"#并行优化\" class=\"headerlink\" title=\"并行优化\"></a>并行优化</h4><p>由于通过提升CPU频率已经达到瓶颈，所以开始推出多核CPU，通过提升“吞吐率”而不是“响应时间”，来达到目的。</p>\n<p>但是，并不是所有问题，都可以通过并行提高性能来解决。如果想要使用这种思想，需要满足这样几个条件。</p>\n<p>1、需要进行的计算，本身可以分解成几个可以并行的任务。<br>2、需要能够分解好问题，并确保几个人的结果能够汇总到一起。<br>3、在“汇总”这个阶段，是没有办法并行进行的，还是得顺序执行，一步一步来。</p>\n<p>所以并行计算涉及到了一个阿姆达尔定律（Amdahl’s Law）。</p>\n<p>对于一个程序进行优化之后，处理器并行运算之后效率提升的情况。具体可以用这样一个公式来表示：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">优化后的执行时间 &#x3D; 受优化影响的执行时间&#x2F;加速倍数+不受影响的执行时间<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>比如做一段数据的计算， 本来如果整个计算单核完成需要120ns，但是我们可以将这个任务拆分成4个，最后再汇总加起来。</p>\n<p>如果每个任务单独计算需要25ns，加起来汇总需要20ns，那么4个任务并行计算需要<strong>100&#x2F;4+20&#x3D;25ns</strong>。</p>\n<p>即使我们增加更多的并行度来提供加速倍数，比如有100个CPU，整个时间也需要<strong>100&#x2F;100+20&#x3D;21ns</strong>。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/jzy-1.jpeg\"></p>\n<h4 id=\"从编译到汇编，代码怎么变成机器码？\"><a href=\"#从编译到汇编，代码怎么变成机器码？\" class=\"headerlink\" title=\"从编译到汇编，代码怎么变成机器码？\"></a>从编译到汇编，代码怎么变成机器码？</h4><p>如下C语言程序例子：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">&#x2F;&#x2F; test.cint main()&#123;\n  int a &#x3D; 1;\n  int b &#x3D; 2;\n  a &#x3D; a + b;\n&#125;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>我们给两个变量 a、b分别赋值1、2，然后再将a、b两个变量中的值加在一起，重新赋值给了a整个变量。</p>\n<p>要让这段程序在一个Linux操作系统上跑起来，我们需要把整个程序翻译成一个汇编语言（ASM，Assembly Language）的程序，这个过程我们一般叫编译（Compile）成汇编代码。</p>\n<p>针对汇编代码，我们可以再用汇编器（Assembler）翻译成机器码（Machine Code）。这些机器码由“0”和“1”组成的机器语言表示。这一条条机器码，就是一条条的计算机指令。这样一串串的16进制数字，就是我们CPU能够真正认识的计算机指令。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/jzy-3.png\"></p>\n<p>汇编代码其实就是“给程序员看的机器码”，也正因为这样，机器码和汇编代码是一一对应的。我们人类很容易记住add、mov这些用英文表示的指令，而8b 45 f8这样的指令，由于很难一下子看明白是在干什么，所以会非常难以记忆。所以我们需要汇编代码。</p>\n<h4 id=\"指令是如何被执行的\"><a href=\"#指令是如何被执行的\" class=\"headerlink\" title=\"指令是如何被执行的\"></a>指令是如何被执行的</h4><p>一个CPU里面会有很多种不同功能的寄存器。我这里给你介绍三种比较特殊的。</p>\n<p>1、PC寄存器（Program Counter Register），也叫指令地址寄存器（Instruction Address Register）。它就是用来存放下一条需要执行的计算机指令的内存地址。</p>\n<p>2、指令寄存器（Instruction Register），用来存放当前正在执行的指令。</p>\n<p>3、条件码寄存器（Status Register），用里面的一个一个标记位（Flag），存放CPU进行算术或者逻辑计算的结果。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/zjy-3.jpeg\"></p>\n<p>实际上，一个程序执行的时候，CPU会根据PC寄存器里的地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。可以看到，一个程序的一条条指令，在内存里面是连续保存的，也会一条条顺序加载。</p>\n<h4 id=\"程序的执行和跳转\"><a href=\"#程序的执行和跳转\" class=\"headerlink\" title=\"程序的执行和跳转\"></a>程序的执行和跳转</h4><p>现在就来看一个包含if…else的简单程序。</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">&#x2F;&#x2F; test.c\n#include &lt;time.h&gt;\n#include &lt;stdlib.h&gt; \nint main() &#123; \n    srand(time(NULL)); \n    int r &#x3D; rand() % 2; \n    int a &#x3D; 10; \n    if (r &#x3D;&#x3D; 0) &#123; \n        a &#x3D; 1; \n        &#125; else &#123; \n        a &#x3D; 2; \n&#125;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>把这个程序编译成汇编代码。</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">if (r &#x3D;&#x3D; 0)\n3b: 83 7d fc 00     cmp DWORD PTR [rbp-0x4],0x0 \n3f: 75 09           jne 4a &lt;main+0x4a&gt;\n &#123;\n     a &#x3D; 1;\n41: c7 45 f8 01 00 00 00      mov DWORD PTR [rbp-0x8],0x1 \n48: eb 07                     jmp 51 &lt;main+0x51&gt;\n    &#125; \n    else \n    &#123;\n         a &#x3D; 2;\n4a: c7 45 f8 02 00 00 00   mov DWORD PTR [rbp-0x8],0x2\n51: b8 00 00 00 00         mov eax,0x0\n&#125;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>可以看到，这里对于r &#x3D;&#x3D; 0的条件判断，被编译成了cmp和jne这两条指令。</p>\n<p>对于：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">cmp DWORD PTR [rbp-0x4],0x0<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>cmp指令比较了前后两个操作数的值，这里的DWORD PTR代表操作的数据类型是32位的整数，而[rbp-0x4]则是一个寄存器的地址。所以，第一个操作数就是从寄存器里拿到的变量r的值。第二个操作数0x0就是我们设定的常量0的16进制表示。cmp指令的比较结果，会存入到条件码寄存器当中去。</p>\n<p>在这里，如果比较的结果是False，也就是0，就把零标志条件码（对应的条件码是ZF，Zero Flag）设置为1。</p>\n<p>cmp指令执行完成之后，PC寄存器会自动自增，开始执行下一条jne的指令。</p>\n<p>对于：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">jne 4a &lt;main+0x4a&gt;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>jne指令，是jump if not equal的意思，它会查看对应的零标志位。如果为0，会跳转到后面跟着的操作数4a的位置。这个4a，对应这里汇编代码的行号，也就是上面设置的else条件里的第一条指令。</p>\n<p>当跳转发生的时候，PC寄存器就不再是自增变成下一条指令的地址，而是被直接设置成这里的4a这个地址。这个时候，CPU再把4a地址里的指令加载到指令寄存器中来执行。</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">4a: c7 45 f8 02 00 00 00     mov DWORD PTR [rbp-0x8],0x2 \n51: b8 00 00 00 00           mov eax,0x0<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n<p>4a的指令，实际是一条mov指令，第一个操作数和前面的cmp指令一样，是另一个32位整型的寄存器地址，以及对应的2的16进制值0x2。mov指令把2设置到对应的寄存器里去，相当于一个赋值操作。然后，PC寄存器里的值继续自增，执行下一条mov指令。</p>\n<p>下一条指令也是mov，第一个操作数eax，代表累加寄存器，第二个操作数0x0则是16进制的0的表示。这条指令其实没有实际的作用，它的作用是一个占位符。</p>\n<h4 id=\"函数调用\"><a href=\"#函数调用\" class=\"headerlink\" title=\"函数调用\"></a>函数调用</h4><p>我们先来看个例子：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">&#x2F;&#x2F; function_example.c \n#include &lt;stdio.h&gt; \nint static add(int a, int b) &#123;\n return a+b; \n&#125; \nint main() \n&#123; \nint x &#x3D; 5; \nint y &#x3D; 10; \nint u &#x3D; add(x, y);\n&#125;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>我们把这个程序编译之后：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">int static add(int a, int b) \n&#123;\n 0: 55 push rbp \n1: 48 89 e5 mov rbp,rsp \n4: 89 7d fc mov DWORD PTR [rbp-0x4],edi \n7: 89 75 f8 mov DWORD PTR [rbp-0x8],esi \nreturn a+b; \na: 8b 55 fc mov edx,DWORD PTR [rbp-0x4] \nd: 8b 45 f8 mov eax,DWORD PTR [rbp-0x8] \n10:  5d pop rbp \n13: c3 ret 0000000000000014 &lt;main&gt;:\n int main() \n&#123; \n14: 55 push rbp \n15: 48 89 e5 mov rbp,rsp \n18: 48 83 ec 10 sub rsp,0x10 \n    int x &#x3D; 5; \n1c: c7 45 fc 05 00 00 00 mov DWORD PTR [rbp-0x4],0x5 \n    int y &#x3D; 10; \n23: c7 45 f8 0a 00 00 00 mov DWORD PTR [rbp-0x8],0xa \n    int u &#x3D; add(x, y); \n2a: 8b 55 f8 mov edx,DWORD PTR [rbp-0x8] \n2d: 8b 45 fc mov eax,DWORD PTR [rbp-0x4] 30: 89 d6 mov esi,edx \n32: 89 c7 mov edi,eax 34: e8 c7 ff ff ff call 0 &lt;add&gt; \n39: 89 45 f4 mov DWORD PTR [rbp-0xc],eax \n3c: b8 00 00 00 00 mov eax,0x0 \n&#125; \n41: c9 leave \n42: c3 ret01 d0 add eax,edx \n&#125; \n12:<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>在add函数编译之后，代码先执行了一条push指令和一条mov指令；在函数执行结束的时候，又执行了一条pop和一条ret指令。</p>\n<p>add函数的第0行，push rbp这个指令，就是在进行压栈。这里的rbp又叫栈帧指针（Frame Pointer），是一个存放了当前栈帧位置的寄存器。push rbp就把之前调用函数的返回地址，压到栈顶。</p>\n<p>接着，第1行的一条命令mov rbp, rsp里，则是把rsp这个栈指针（Stack Pointer）的值复制到rbp里，而rsp始终会指向栈顶。这个命令意味着，rbp这个栈帧指针指向的返回地址，变成当前最新的栈顶，也就是add函数的返回地址了。</p>\n<p>而在函数add执行完成之后，又会分别调用第12行的pop rbp来将当前的栈顶出栈，然后调用第13行的ret指令，将程序的控制权返回到出栈后的栈顶，也就是main函数的返回地址。</p>\n<h4 id=\"拆解程序执行\"><a href=\"#拆解程序执行\" class=\"headerlink\" title=\"拆解程序执行\"></a>拆解程序执行</h4><p>实际上，“C语言代码-汇编代码-机器码” 这个过程，在我们的计算机上进行的时候是由两部分组成的。</p>\n<p>第一个部分由编译（Compile）、汇编（Assemble）以及链接（Link）三个阶段组成。在这三个阶段完成之后，我们就生成了一个可执行文件。</p>\n<p>第二部分，我们通过装载器（Loader）把可执行文件装载（Load）到内存中。CPU从内存中读取指令和数据，来开始真正执行程序。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705162525.png\"></p>\n<h4 id=\"静态链接\"><a href=\"#静态链接\" class=\"headerlink\" title=\"静态链接\"></a>静态链接</h4><p>程序的链接，是把对应的不同文件内的代码段，合并到一起，成为最后的可执行文件。</p>\n<p>在可执行文件里，我们可以看到，对应的函数名称，像add、main等等，乃至你自己定义的全局可以访问的变量名称对应的地址，存储在一个叫作符号表（Symbols Table）的位置里。符号表相当于一个地址簿，把名字和地址关联了起来。</p>\n<p>经过程序的链接之后，main函数里调用add的跳转地址，不再是下一条指令的地址了，而是add函数的入口地址了。</p>\n<p>链接器会扫描所有输入的目标文件，然后把所有符号表里的信息收集起来，构成一个全局的符号表。然后再根据重定位表，把所有不确定要跳转地址的代码，根据符号表里面存储的地址，进行一次修正。最后，把所有的目标文件的对应段进行一次合并，变成了最终的可执行代码。</p>\n<p>这个合并代码段的方法，是叫<em><strong>静态链接</strong></em>。</p>\n<h4 id=\"动态链接\"><a href=\"#动态链接\" class=\"headerlink\" title=\"动态链接\"></a>动态链接</h4><p>在动态链接的过程中，我们想要“链接”的，不是存储在硬盘上的目标文件代码，而是加载到内存中的<em><strong>共享库</strong></em>（Shared Libraries）。</p>\n<p>要想要在程序运行的时候共享代码，也有一定的要求，就是这些机器码必须是“地址无关”的。换句话说就是，这段代码，无论加载在哪个内存地址，都能够正常执行。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705162632.png\"></p>\n<p>动态代码库内部的变量和函数调用都是使用相对地址。因为整个共享库是放在一段连续的虚拟内存地址中的，无论装载到哪一段地址，不同指令之间的相对地址都是不变的。</p>\n<h4 id=\"装载程序\"><a href=\"#装载程序\" class=\"headerlink\" title=\"装载程序\"></a>装载程序</h4><p>在运行这些可执行文件的时候，我们其实是通过一个装载器，解析ELF或者PE格式的可执行文件。装载器会把对应的指令和数据加载到内存里面来，让CPU去执行。</p>\n<p>装载器需要满足两个要求：</p>\n<p>1、可执行程序加载后占用的内存空间应该是连续的。因为CPU在执行指令的时候，程序计数器是顺序地一条一条指令执行下去。</p>\n<p>2、我们需要同时加载很多个程序，并且不能让程序自己规定在内存中加载的位置。因为我们现在的计算机通常会同时运行很多个程序，可能你想要的内存地址已经被其他加载了的程序占用了。</p>\n<p>基于上面，我们需要在内存空间地址和整个程序指令指定的内存地址做一个映射。</p>\n<p>把指令里用到的内存地址叫作<em><strong>虚拟内存地址</strong></em>（Virtual Memory Address），实际在内存硬件里面的空间地址，我们叫<em><strong>物理内存地址</strong></em>（Physical Memory Address）。</p>\n<h4 id=\"内存分页\"><a href=\"#内存分页\" class=\"headerlink\" title=\"内存分页\"></a>内存分页</h4><p>分页是把整个物理内存空间切成一段段固定尺寸的大小。而对应的程序所需要占用的虚拟内存空间，也会同样切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。</p>\n<p>从虚拟内存到物理内存的映射，不再是拿整段连续的内存的物理地址，而是按照一个一个页来的。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705162836.png\"></p>\n<p>分页之后避免了整个程序和硬盘进行交换而产生性能瓶颈。即使内存空间不够，需要让现有的、正在运行的其他程序，通过内存交换释放出一些内存的页出来，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，让整个机器被内存交换的过程给卡住。</p>\n<h4 id=\"浮点数和定点数\"><a href=\"#浮点数和定点数\" class=\"headerlink\" title=\"浮点数和定点数\"></a>浮点数和定点数</h4><p>我们先来看一个问题，在Chrome浏览器里面通过开发者工具，打开浏览器里的Console，在里面输入“0.3 + 0.6”：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">&gt;&gt;&gt; 0.3 + 0.6\n0.8999999999999999<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>下面我们来一步步解释，为什么会这样。</p>\n<h4 id=\"定点数\"><a href=\"#定点数\" class=\"headerlink\" title=\"定点数\"></a>定点数</h4><p>如果我们用32个比特表示整数，用4个比特来表示0～9的整数，那么32个比特就可以表示8个这样的整数。</p>\n<p>然后我们把最右边的2个0～9的整数，当成小数部分；把左边6个0～9的整数，当成整数部分。这样，我们就可以用32个比特，来表示从0到999999.99这样1亿个实数了。</p>\n<p>这种用二进制来表示十进制的编码方式，叫作BCD编码。这种小数点固定在某一位的方式，我们也就把它称为定点数。</p>\n<p>缺点：</p>\n<p>第一，这样的表示方式有点“浪费”。本来32个比特我们可以表示40亿个不同的数，但是在BCD编码下，只能表示1亿个数。</p>\n<p>第二，这样的表示方式没办法同时表示很大的数字和很小的数字。</p>\n<h4 id=\"浮点数\"><a href=\"#浮点数\" class=\"headerlink\" title=\"浮点数\"></a>浮点数</h4><p>我们在表示一个很大的数的时候，通常可以用科学计数法来表示。</p>\n<p>在计算机里，我也可以用科学计数法来表示实数。浮点数的科学计数法的表示，有一个IEEE的标准，它定义了两个基本的格式。一个是用32比特表示单精度的浮点数，也就是我们常常说的float或者float32类型。另外一个是用64比特表示双精度的浮点数，也就是我们平时说的double或者float64类型。</p>\n<h5 id=\"单精度\"><a href=\"#单精度\" class=\"headerlink\" title=\"单精度\"></a>单精度</h5><p>单精度的32个比特可以分成三部分。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705163020.png\"></p>\n<p>第一部分是一个符号位，用来表示是正数还是负数。我们一般用s来表示。在浮点数里，我们不像正数分符号数还是无符号数，所有的浮点数都是有符号的。</p>\n<p>接下来是一个8个比特组成的指数位。我们一般用e来表示。8个比特能够表示的整数空间，就是0～255。我们在这里用1～254映射到-126～127这254个有正有负的数上。</p>\n<p>最后，是一个23个比特组成的有效数位。我们用f来表示。综合科学计数法，我们的浮点数就可以表示成下面这样：<br><code>$(-1)^s×1.f×2^e$</code></p>\n<h5 id=\"特殊值的表示\"><a href=\"#特殊值的表示\" class=\"headerlink\" title=\"特殊值的表示\"></a>特殊值的表示</h5><p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705163120.png\"></p>\n<p>以0.5为例子。0.5的符号为s应该是0，f应该是0，而e应该是-1，也就是<br>***$0.5&#x3D; (-1)^0×1.0×2^{-1}&#x3D;0.5$***，对应的浮点数表示，就是32个比特。</p>\n<p>不考虑符号的话，浮点数能够表示的最小的数和最大的数，差不多是***$1.17×10^{-38}$<em><strong>和</strong></em>$3.40×10^{38}$***。</p>\n<p>回到我们最开头，为什么我们用<em><strong>0.3 + 0.6</strong></em>不能得到0.9呢？这是因为，浮点数没有办法精确表示0.3、0.6和0.9。</p>\n<h5 id=\"浮点数的二进制转化\"><a href=\"#浮点数的二进制转化\" class=\"headerlink\" title=\"浮点数的二进制转化\"></a>浮点数的二进制转化</h5><p>我们输入一个任意的十进制浮点数，背后都会对应一个二进制表示。</p>\n<p>比如：9.1，那么，首先，我们把这个数的整数部分，变成一个二进制。这里的9，换算之后就是1001。</p>\n<p>接着，我们把对应的小数部分也换算成二进制。和整数的二进制表示采用“除以2，然后看余数”的方式相比，小数部分转换成二进制是用一个相似的反方向操作，就是乘以2，然后看看是否超过1。如果超过1，我们就记下1，并把结果减去1，进一步循环操作。在这里，我们就会看到，0.1其实变成了一个无限循环的二进制小数，0.000110011。这里的“0011”会无限循环下去。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705163229.png\"></p>\n<p>结果就是：***$1.0010$$0011$$0011… × 2^3$***</p>\n<p>这里的符号位s &#x3D; 0，对应的有效位f&#x3D;001000110011…。因为f最长只有23位，那这里“0011”无限循环，最多到23位就截止了。于是，f&#x3D;00100011001100110011 001。最后的一个“0011”循环中的最后一个“1”会被截断掉。</p>\n<p>对应的指数为e，代表的应该是3。因为指数位有正又有负，所以指数位在127之前代表负数，之后代表正数，那3其实对应的是加上127的偏移量130，转化成二进制，就是130，对应的就是指数位的二进制，表示出来就是10000010。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705163301.png\"></p>\n<p>最终得到的二进制表示就变成了：</p>\n<p><code>010000010 0010 0011001100110011 001</code></p>\n<p>如果我们再把这个浮点数表示换算成十进制， 实际准确的值是9.09999942779541015625。</p>\n<h5 id=\"浮点数的加法和精度损失\"><a href=\"#浮点数的加法和精度损失\" class=\"headerlink\" title=\"浮点数的加法和精度损失\"></a>浮点数的加法和精度损失</h5><p>浮点数的加法是：先对齐、再计算。</p>\n<p>那我们在计算0.5+0.125的浮点数运算的时候，首先要把两个的指数位对齐，也就是把指数位都统一成两个其中较大的-1。对应的有效位1.00…也要对应右移两位，因为f前面有一个默认的1，所以就会变成0.01。然后我们计算两者相加的有效位1.f，就变成了有效位1.01，而指数位是-1，这样就得到了我们想要的加法后的结果。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705163357.png\"></p>\n<p>其中指数位较小的数，需要在有效位进行右移，在右移的过程中，最右侧的有效位就被丢弃掉了。这会导致对应的指数位较小的数，在加法发生之前，就丢失精度。</p>\n<h4 id=\"指令周期（Instruction-Cycle）\"><a href=\"#指令周期（Instruction-Cycle）\" class=\"headerlink\" title=\"指令周期（Instruction Cycle）\"></a>指令周期（Instruction Cycle）</h4><p>计算机每执行一条指令的过程，可以分解成这样几个步骤。</p>\n<ul>\n<li>Fetch（取得指令），也就是从PC寄存器里找到对应的指令地址，根据指令地址从内存里把具体的指令，加载到指令寄存器中，然后把PC寄存器自增，好在未来执行下一条指令。</li>\n<li>Decode（指令译码），也就是根据指令寄存器里面的指令，解析成要进行什么样的操作，是R、I、J中的哪一种指令，具体要操作哪些寄存器、数据或者内存地址。</li>\n<li>Execute（执行指令），也就是实际运行对应的R、I、J这些特定的指令，进行算术逻辑操作、数据传输或者直接的地址跳转。</li>\n<li>Fetch - Decode - Execute循环称之为指令周期（Instruction Cycle）。</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705163606.png\"></p>\n<p>在取指令的阶段，我们的指令是放在存储器里的，实际上，通过PC寄存器和指令寄存器取出指令的过程，是由<em><strong>控制器</strong></em>（Control Unit）操作的。指令的解码过程，也是由控制器进行的。一旦到了执行指令阶段，无论是进行算术操作、逻辑操作的R型指令，还是进行数据传输、条件分支的I型指令，都是由<em><strong>算术逻辑单元</strong></em>（ALU）操作的，也就是由运算器处理的。不过，如果是一个简单的无条件地址跳转，那么我们可以直接在控制器里面完成，不需要用到运算器。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705163606.png\"></p>\n<h4 id=\"时序逻辑电路\"><a href=\"#时序逻辑电路\" class=\"headerlink\" title=\"时序逻辑电路\"></a>时序逻辑电路</h4><p>有一些电路，只需要给定输入，就能得到固定的输出。这样的电路，我们称之为<em><strong>组合逻辑电路</strong></em>（Combinational Logic Circuit）。</p>\n<p>时序逻辑电路有以下几个特点：</p>\n<p>1、自动运行，时序电路接通之后可以不停地开启和关闭开关，进入一个自动运行的状态。</p>\n<p>2、<em><strong>存储</strong></em>。通过时序电路实现的触发器，能把计算结果存储在特定的电路里面，而不是像组合逻辑电路那样，一旦输入有任何改变，对应的输出也会改变。</p>\n<p>3、时序电路使得不同的事件按照时间顺序发生。</p>\n<p>最常见的就是D触发器，电路的输出信号不单单取决于当前的输入信号，还要取决于输出信号之前的状态。</p>\n<h4 id=\"PC寄存器\"><a href=\"#PC寄存器\" class=\"headerlink\" title=\"PC寄存器\"></a>PC寄存器</h4><p>PC寄存器就是程序计数器。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705163813.png\"></p>\n<p>加法器的两个输入，一个始终设置成1，另外一个来自于一个D型触发器A。我们把加法器的输出结果，写到这个D型触发器A里面。于是，D型触发器里面的数据就会在固定的时钟信号为1的时候更新一次。</p>\n<p>这样，我们就有了一个每过一个时钟周期，就能固定自增1的自动计数器了。</p>\n<h4 id=\"最简单的CPU流程\"><a href=\"#最简单的CPU流程\" class=\"headerlink\" title=\"最简单的CPU流程\"></a>最简单的CPU流程</h4><p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705163844.png\"></p>\n<p>1、首先，有一个自动计数器会随着时钟主频不断地自增，来作为我们的PC寄存器。</p>\n<p>2、在这个自动计数器的后面，我们连上一个译码器（用来寻址，将指令内存地址转换成指令）。译码器还要同时连着我们通过大量的D触发器组成的内存。</p>\n<p>3、自动计数器会随着时钟主频不断自增，从译码器当中，找到对应的计数器所表示的内存地址，然后读取出里面的CPU指令。</p>\n<p>4、读取出来的CPU指令会通过我们的CPU时钟的控制，写入到一个由D触发器组成的寄存器，也就是指令寄存器当中。</p>\n<p>5、在指令寄存器后面，我们可以再跟一个译码器。这个译码器不再是用来寻址的了，而是把我们拿到的指令，解析成opcode和对应的操作数。</p>\n<p>6、当我们拿到对应的opcode和操作数，对应的输出线路就要连接ALU，开始进行各种算术和逻辑运算。对应的计算结果，则会再写回到D触发器组成的寄存器或者内存当中。</p>\n<h4 id=\"指令流水线\"><a href=\"#指令流水线\" class=\"headerlink\" title=\"指令流水线\"></a>指令流水线</h4><p>指令流水线指的是把一个指令拆分成一个一个小步骤，从而来减少单条指令执行的“延时”。通过同时在执行多条指令的不同阶段，我们提升了CPU的“吞吐率”。</p>\n<p>如果我们把一个指令拆分成“取指令-指令译码-执行指令”这样三个部分，那这就是一个三级的流水线。如果我们进一步把“执行指令”拆分成“ALU计算（指令执行）-内存访问-数据写回”，那么它就会变成一个五级的流水线。</p>\n<p>五级的流水线，就表示我们在同一个时钟周期里面，同时运行五条指令的不同阶段。</p>\n<p>我们可以看这样一个例子。我们顺序执行这样三条指令。</p>\n<p>1、一条整数的加法，需要200ps。</p>\n<p>2、一条整数的乘法，需要300ps。</p>\n<p>3、一条浮点数的乘法，需要600ps</p>\n<p>如果我们是在单指令周期的CPU上运行，最复杂的指令是一条浮点数乘法，那就需要600ps。那这三条指令，都需要600ps。三条指令的执行时间，就需要1800ps。</p>\n<p>如果我们采用的是6级流水线CPU，每一个Pipeline的Stage都只需要100ps。那么，在这三个指令的执行过程中，在指令1的第一个100ps的Stage结束之后，第二条指令就开始执行了。在第二条指令的第一个100ps的Stage结束之后，第三条指令就开始执行了。这种情况下，这三条指令顺序执行所需要的总时间，就是800ps。那么在1800ps内，使用流水线的CPU比单指令周期的CPU就可以多执行一倍以上的指令数。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705164010.png\"></p>\n<h4 id=\"流水线设计CPU的风险\"><a href=\"#流水线设计CPU的风险\" class=\"headerlink\" title=\"流水线设计CPU的风险\"></a>流水线设计CPU的风险</h4><h5 id=\"结构冒险\"><a href=\"#结构冒险\" class=\"headerlink\" title=\"结构冒险\"></a>结构冒险</h5><p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705164043.png\"></p>\n<p>可以看到，在第1条指令执行到访存（MEM）阶段的时候，流水线里的第4条指令，在执行取指令（Fetch）的操作。访存和取指令，都要进行内存数据的读取。但是内存在一个时钟周期是没办法都做的。</p>\n<p>解决办法：在高速缓存层面拆分成指令缓存和数据缓存</p>\n<p>在CPU内部的高速缓存部分进行了区分，把高速缓存分成了指令缓存（Instruction Cache）和数据缓存（Data Cache）两部分。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705164106.png\"></p>\n<h5 id=\"数据冒险\"><a href=\"#数据冒险\" class=\"headerlink\" title=\"数据冒险\"></a>数据冒险</h5><p><em><strong>1、先写后读</strong></em></p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">int main() \n&#123; int a &#x3D; 1;\n  int b &#x3D; 2;\n  a &#x3D; a + 2;\n  b &#x3D; a + 3; &#125;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>这里需要保证a和b的值先赋，然后才能进行准确的运算。这个先写后读的依赖关系，我们一般被称之为数据依赖，也就是Data Dependency。</p>\n<p><em><strong>2、先读后写</strong></em></p>\n<pre class=\"line-numbers language-int\" data-language=\"int\"><div class=\"caption\"><span>main()</span></div><code class=\"language-int\">&#123; int a &#x3D; 1;\n  int b &#x3D; 2;\n  a &#x3D; b + a; \n  b &#x3D; a + b; &#125;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>这里我们先要读出a &#x3D; b+a，然后才能正确的写入b的值。这个先读后写的依赖，一般被叫作反依赖，也就是Anti-Dependency。</p>\n<p><em><strong>3、写后再写</strong></em></p>\n<pre class=\"line-numbers language-int\" data-language=\"int\"><div class=\"caption\"><span>main()</span></div><code class=\"language-int\">&#123; int a &#x3D; 1;\n  a &#x3D; 2; &#125;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>很明显，两个写入操作不能乱，要不然最终结果就是错误的。这个写后再写的依赖，一般被叫作输出依赖，也就是Output Dependency。</p>\n<p>解决办法：<em><strong>流水线停顿</strong></em>（Pipeline Stall）</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705164337.png\"></p>\n<p>如果我们发现了后面执行的指令，会对前面执行的指令有数据层面的依赖关系，那最简单的办法就是“再等等”。我们在进行指令译码的时候，会拿到对应指令所需要访问的寄存器和内存地址。</p>\n<p>在实践过程中，在执行后面的操作步骤前面，插入一个NOP操作，也就是执行一个其实什么都不干的操作。</p>\n<p>在执行的代码中，一旦遇到 if…else 这样的条件分支，或者 for&#x2F;while 循环的时候会发生类似cmp比较指令、jmp和jle这样的条件跳转指令。</p>\n<p>在jmp指令发生的时候，CPU可能会跳转去执行其他指令。jmp后的那一条指令是否应该顺序加载执行，在流水线里面进行取指令的时候，我们没法知道。要等jmp指令执行完成，去更新了PC寄存器之后，我们才能知道，是否执行下一条指令，还是跳转到另外一个内存地址，去取别的指令。</p>\n<p>解决办法： </p>\n<p><em><strong>缩短分支延迟</strong></em></p>\n<p>条件跳转指令其实进行了两种电路操作。</p>\n<p>第一种，是进行条件比较。</p>\n<p>第二种，是进行实际的跳转，也就是把要跳转的地址信息写入到PC寄存器。无论是opcode，还是对应的条件码寄存器，还是我们跳转的地址，都是在指令译码（ID）的阶段就能获得的。而对应的条件码比较的电路，只要是简单的逻辑门电路就可以了，并不需要一个完整而复杂的ALU。</p>\n<p>所以，我们可以将条件判断、地址跳转，都提前到指令译码阶段进行，而不需要放在指令执行阶段。对应的，我们也要在CPU里面设计对应的旁路，在指令译码阶段，就提供对应的判断比较的电路。</p>\n<p><em><strong>分支预测</strong></em></p>\n<p>最简单的分支预测技术，叫作“<em><strong>假装分支不发生</strong></em>”。顾名思义，自然就是仍然按照顺序，把指令往下执行。</p>\n<p>如果分支预测失败了呢？那我们就把后面已经取出指令已经执行的部分，给丢弃掉。这个丢弃的操作，在流水线里面，叫作Zap或者Flush。CPU不仅要执行后面的指令，对于这些已经在流水线里面执行到一半的指令，我们还需要做对应的清除操作。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705164610.png\"></p>\n<p><em><strong>动态分支预测</strong></em></p>\n<p>就是记录当前分支的比较情况，直接用当前分支的比较情况，来预测下一次分支时候的比较情况。</p>\n<p>例子：</p>\n<pre class=\"line-numbers language-public\" data-language=\"public\"><div class=\"caption\"><span>class BranchPrediction &#123;</span></div><code class=\"language-public\">    public static void main(String args[]) &#123;        \n        long start &#x3D; System.currentTimeMillis();\n        for (int i &#x3D; 0; i &lt; 100; i++) &#123;\n            for (int j &#x3D; 0; j &lt;1000; j ++) &#123;\n                for (int k &#x3D; 0; k &lt; 10000; k++) &#123;\n                &#125;\n            &#125;\n        &#125;\n        long end &#x3D; System.currentTimeMillis();\n        System.out.println(&quot;Time spent is &quot; + (end - start));\n                \n        start &#x3D; System.currentTimeMillis();\n        for (int i &#x3D; 0; i &lt; 10000; i++) &#123;\n            for (int j &#x3D; 0; j &lt;1000; j ++) &#123;\n                for (int k &#x3D; 0; k &lt; 100; k++) &#123;\n                &#125;\n            &#125;\n        &#125;\n        end &#x3D; System.currentTimeMillis();\n        System.out.println(&quot;Time spent is &quot; + (end - start) + &quot;ms&quot;);\n    &#125;\n&#125;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>输出：</p>\n<pre class=\"line-numbers language-Time\" data-language=\"Time\"><div class=\"caption\"><span>spent in first loop is 5ms</span></div><code class=\"language-Time\">Time spent in second loop is 15ms<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705164706.png\"></p>\n<p>分支预测策略最简单的一个方式，自然是“<em><strong>假定分支不发生</strong></em>”。对应到上面的循环代码，就是循环始终会进行下去。在这样的情况下，上面的第一段循环，也就是内层 k 循环10000次的代码。每隔10000次，才会发生一次预测上的错误。而这样的错误，在第二层 j 的循环发生的次数，是1000次。</p>\n<p>最外层的 i 的循环是100次。每个外层循环一次里面，都会发生1000次最内层 k 的循环的预测错误，所以一共会发生 100 × 1000 &#x3D; 10万次预测错误。</p>\n<h5 id=\"操作数前推\"><a href=\"#操作数前推\" class=\"headerlink\" title=\"操作数前推\"></a>操作数前推</h5><p>通过流水线停顿可以解决资源竞争产生的问题，但是，插入过多的NOP操作，意味着我们的CPU总是在空转，干吃饭不干活。所以我们提出了操作数前推这样的解决方案。</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">1、  add $t0, $s2,$s1\n2、  add $s2, $s1,$t0<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>第一条指令，把 s1 和 s2 寄存器里面的数据相加，存入到 t0 这个寄存器里面。</p>\n<p>第二条指令，把 s1 和 t0 寄存器里面的数据相加，存入到 s2 这个寄存器里面。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705164838.png\"></p>\n<p>我们要在第二条指令的译码阶段之后，插入对应的NOP指令，直到前一天指令的数据写回完成之后，才能继续执行。但是这样浪费了两个时钟周期。</p>\n<p>这个时候完全可以在第一条指令的执行阶段完成之后，直接将结果数据传输给到下一条指令的ALU。然后，下一条指令不需要再插入两个NOP阶段，就可以继续正常走到执行阶段。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705164856.png\"></p>\n<p>这样的解决方案，我们就叫作<em><strong>操作数前推</strong></em>（Operand Forwarding），或者<em><strong>操作数旁路</strong></em>（Operand Bypassing）。</p>\n<h4 id=\"CPU指令乱序执行\"><a href=\"#CPU指令乱序执行\" class=\"headerlink\" title=\"CPU指令乱序执行\"></a>CPU指令乱序执行</h4><p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705164934.png\"></p>\n<p>1、在取指令和指令译码的时候，乱序执行的CPU和其他使用流水线架构的CPU是一样的。它会一级一级顺序地进行取指令和指令译码的工作。</p>\n<p>2、在指令译码完成之后，CPU不会直接进行指令执行，而是进行一次指令分发，把指令发到一个叫作保留站（Reservation Stations）的地方。</p>\n<p>3、这些指令不会立刻执行，而要等待它们所依赖的数据，传递给它们之后才会执行。</p>\n<p>4、一旦指令依赖的数据来齐了，指令就可以交到后面的功能单元（Function Unit，FU），其实就是ALU，去执行了。我们有很多功能单元可以并行运行，但是不同的功能单元能够支持执行的指令并不相同。</p>\n<p>5、指令执行的阶段完成之后，我们并不能立刻把结果写回到寄存器里面去，而是把结果再存放到一个叫作重排序缓冲区（Re-Order Buffer，ROB）的地方。</p>\n<p>6、在重排序缓冲区里，我们的CPU会按照取指令的顺序，对指令的计算结果重新排序。只有排在前面的指令都已经完成了，才会提交指令，完成整个指令的运算结果。</p>\n<p>7、实际的指令的计算结果数据，并不是直接写到内存或者高速缓存里，而是先写入存储缓冲区（Store Buffer面，最终才会写入到高速缓存和内存里。</p>\n<p>8、在乱序执行的情况下，只有CPU内部指令的执行层面，可能是“乱序”的。</p>\n<p>例子：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">a &#x3D; b + c\nd &#x3D; a * e\nx &#x3D; y * z<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n\n<p>里面的 d 依赖于 a 的计算结果，不会在 a 的计算完成之前执行。但是我们的CPU并不会闲着，因为 x &#x3D; y * z 的指令同样会被分发到保留站里。因为 x 所依赖的 y 和 z 的数据是准备好的， 这里的乘法运算不会等待计算 d，而会先去计算 x 的值。</p>\n<p>如果我们只有一个FU能够计算乘法，那么这个FU并不会因为 d 要等待 a 的计算结果，而被闲置，而是会先被拿去计算 x。</p>\n<p>在 x 计算完成之后，d 也等来了 a 的计算结果。这个时候，我们的FU就会去计算出 d 的结果。然后在重排序缓冲区里，把对应的计算结果的提交顺序，仍然设置成 a -&gt; d -&gt; x，而计算完成的顺序是 x -&gt; a -&gt; d。</p>\n<p>在这整个过程中，整个计算乘法的FU都没有闲置，这也意味着我们的CPU的吞吐率最大化了。</p>\n<p>乱序执行，极大地提高了CPU的运行效率。核心原因是，现代CPU的运行速度比访问主内存的速度要快很多。如果完全采用顺序执行的方式，很多时间都会浪费在前面指令等待获取内存数据的时间里。CPU不得不加入NOP操作进行空转。</p>\n<h4 id=\"超线程\"><a href=\"#超线程\" class=\"headerlink\" title=\"超线程\"></a>超线程</h4><p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705165148.png\"></p>\n<p>超线程的CPU，其实是把一个物理层面CPU核心，“伪装”成两个逻辑层面的CPU核心。这个CPU，会在硬件层面增加很多电路，使得我们可以在一个CPU核心内部，维护两个不同线程的指令的状态信息。</p>\n<p>比如，在一个物理CPU核心内部，会有双份的PC寄存器、指令寄存器乃至条件码寄存器。这样，这个CPU核心就可以维护两条并行的指令的状态。</p>\n<p>超线程并不是真的去同时运行两个指令，超线程的目的，是在一个线程A的指令，在流水线里停顿的时候，让另外一个线程去执行指令。因为这个时候，CPU的译码器和ALU就空出来了，那么另外一个线程B，就可以拿来干自己需要的事情。这个线程B可没有对于线程A里面指令的关联和依赖。</p>\n<p>所以超线程只在特定的应用场景下效果比较好。一般是在那些各个线程“等待”时间比较长的应用场景下。比如，我们需要应对很多请求的数据库应用，就很适合使用超线程。各个指令都要等待访问内存数据，但是并不需要做太多计算。</p>\n<h5 id=\"SIMD加速矩阵乘法\"><a href=\"#SIMD加速矩阵乘法\" class=\"headerlink\" title=\"SIMD加速矩阵乘法\"></a>SIMD加速矩阵乘法</h5><p>SIMD，中文叫作<em><strong>单指令多数据流</strong></em>（Single Instruction Multiple Data）。</p>\n<p>下面是两段示例程序，一段呢，是通过循环的方式，给一个list里面的每一个数加1。另一段呢，是实现相同的功能，但是直接调用NumPy这个库的add方法。</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">$ python\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import timeit\n&gt;&gt;&gt; a &#x3D; list(range(1000))\n&gt;&gt;&gt; b &#x3D; np.array(range(1000))\n&gt;&gt;&gt; timeit.timeit(&quot;[i + 1 for i in a]&quot;, setup&#x3D;&quot;from __main__ import a&quot;, number&#x3D;1000000)\n32.82800309999993\n&gt;&gt;&gt; timeit.timeit(&quot;np.add(1, b)&quot;, setup&#x3D;&quot;from __main__ import np, b&quot;, number&#x3D;1000000)\n0.9787889999997788\n&gt;&gt;&gt;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>两个功能相同的代码性能有着巨大的差异，足足差出了30多倍。原因就是，NumPy直接用到了SIMD指令，能够并行进行向量的操作。</p>\n<p>使用循环来一步一步计算的算法呢，一般被称为SISD，也就是单指令单数据（Single Instruction Single Data）的处理方式。如果你手头的是一个多核CPU呢，那么它同时处理多个指令的方式可以叫作MIMD，也就是多指令多数据（Multiple Instruction Multiple Dataa）。</p>\n<p>Intel在引入SSE指令集的时候，在CPU里面添上了8个 128 Bits的寄存器。128 Bits也就是 16 Bytes ，也就是说，一个寄存器一次性可以加载 4 个整数。比起循环分别读取4次对应的数据，时间就省下来了。</p>\n<p>在数据读取到了之后，在指令的执行层面，SIMD也是可以并行进行的。4个整数各自加1，互相之前完全没有依赖，也就没有冒险问题需要处理。只要CPU里有足够多的功能单元，能够同时进行这些计算，这个加法就是4路同时并行的，自然也省下了时间。</p>\n<p>所以，对于那些在计算层面存在大量“数据并行”（Data Parallelism）的计算中，使用SIMD是一个很划算的办法。</p>\n<h5 id=\"异常和中断\"><a href=\"#异常和中断\" class=\"headerlink\" title=\"异常和中断\"></a>异常和中断</h5><h6 id=\"异常\"><a href=\"#异常\" class=\"headerlink\" title=\"异常\"></a>异常</h6><p>关于异常，它其实是一个硬件和软件组合到一起的处理过程。异常的前半生，也就是异常的发生和捕捉，是在硬件层面完成的。但是异常的后半生，也就是说，异常的处理，其实是由软件来完成的。</p>\n<p>计算机会为每一种可能会发生的异常，分配一个异常代码（Exception Number）。有些教科书会把异常代码叫作中断向量（Interrupt Vector）。</p>\n<p>异常发生的时候，通常是CPU检测到了一个特殊的信号。这些信号呢，在组成原理里面，我们一般叫作发生了一个事件（Event）。CPU在检测到事件的时候，其实也就拿到了对应的异常代码。</p>\n<p>这些异常代码里，I&#x2F;O发出的信号的异常代码，是由操作系统来分配的，也就是由软件来设定的。而像加法溢出这样的异常代码，则是由CPU预先分配好的，也就是由硬件来分配的。</p>\n<p>拿到异常代码之后，CPU就会触发异常处理的流程。计算机在内存里，会保留一个异常表（Exception Table）。我们的CPU在拿到了异常码之后，会先把当前的程序执行的现场，保存到程序栈里面，然后根据异常码查询，找到对应的异常处理程序，最后把后续指令执行的指挥权，交给这个异常处理程序。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705165708.png\"></p>\n<h6 id=\"异常的分类\"><a href=\"#异常的分类\" class=\"headerlink\" title=\"异常的分类\"></a>异常的分类</h6><p><em><strong>中断、陷阱、故障和中止</strong></em></p>\n<p>第一种异常叫中断（Interrupt）。顾名思义，自然就是程序在执行到一半的时候，被打断了。</p>\n<p>第二种异常叫陷阱（Trap）。陷阱，其实是我们程序员“故意“主动触发的异常。就好像你在程序里面打了一个断点，这个断点就是设下的一个”陷阱”。</p>\n<p>第三种异常叫故障（Fault）。比如，我们在程序执行的过程中，进行加法计算发生了溢出，其实就是故障类型的异常。</p>\n<p>最后一种异常叫中止（Abort）。与其说这是一种异常类型，不如说这是故障的一种特殊情况。当CPU遇到了故障，但是恢复不过来的时候，程序就不得不中止了。</p>\n<h6 id=\"异常的处理：上下文切换\"><a href=\"#异常的处理：上下文切换\" class=\"headerlink\" title=\"异常的处理：上下文切换\"></a>异常的处理：上下文切换</h6><p>在实际的异常处理程序执行之前，CPU需要去做一次“保存现场”的操作。有了这个操作，我们才能在异常处理完成之后，重新回到之前执行的指令序列里面来。</p>\n<p>因为异常情况往往发生在程序正常执行的预期之外，比如中断、故障发生的时候。所以，除了本来程序压栈要做的事情之外，我们还需要把CPU内当前运行程序用到的所有寄存器，都放到栈里面。最典型的就是条件码寄存器里面的内容。</p>\n<p>像陷阱这样的异常，涉及程序指令在用户态和内核态之间的切换。对应压栈的时候，对应的数据是压到内核栈里，而不是程序栈里。</p>\n<h5 id=\"虚拟机技术\"><a href=\"#虚拟机技术\" class=\"headerlink\" title=\"虚拟机技术\"></a>虚拟机技术</h5><h6 id=\"解释型虚拟机\"><a href=\"#解释型虚拟机\" class=\"headerlink\" title=\"解释型虚拟机\"></a>解释型虚拟机</h6><p>我们把原先的操作系统叫作宿主机（Host），把能够有能力去模拟指令执行的软件，叫作模拟器（Emulator），而实际运行在模拟器上被“虚拟”出来的系统呢，我们叫客户机（Guest VM）。</p>\n<p>例如在windows上跑的Android模拟器，或者能在Windows下运行的游戏机模拟器。</p>\n<p>这种解释执行方式的最大的优势就是，模拟的系统可以跨硬件。比如，Android手机用的CPU是ARM的，而我们的开发机用的是Intel X86的，两边的CPU指令集都不一样，但是一样可以正常运行。</p>\n<p>缺陷：</p>\n<p>第一个是，我们做不到精确的“模拟”。很多的老旧的硬件的程序运行，要依赖特定的电路乃至电路特有的时钟频率，想要通过软件达到100%模拟是很难做到的。</p>\n<p>第二个是这种解释执行的方式，性能实在太差了。因为我们并不是直接把指令交给CPU去执行的，而是要经过各种解释和翻译工作。</p>\n<h6 id=\"Type-1和Type-2虚拟机\"><a href=\"#Type-1和Type-2虚拟机\" class=\"headerlink\" title=\"Type-1和Type-2虚拟机\"></a>Type-1和Type-2虚拟机</h6><p>如果我们需要一个“全虚拟化”的技术，可以在现有的物理服务器的硬件和操作系统上，去跑一个完整的、不需要做任何修改的客户机操作系统（Guest OS），有一个很常用的一个解决方案，就是加入一个中间层。在虚拟机技术里面，这个中间层就叫作虚拟机监视器，英文叫VMM（Virtual Machine Manager）或者Hypervisor。</p>\n<h6 id=\"Type-2虚拟机\"><a href=\"#Type-2虚拟机\" class=\"headerlink\" title=\"Type-2虚拟机\"></a>Type-2虚拟机</h6><p>在Type-2虚拟机里，我们上面说的虚拟机监视器好像一个运行在操作系统上的软件。你的客户机的操作系统呢，把最终到硬件的所有指令，都发送给虚拟机监视器。而虚拟机监视器，又会把这些指令再交给宿主机的操作系统去执行。</p>\n<h6 id=\"Type-1虚拟机\"><a href=\"#Type-1虚拟机\" class=\"headerlink\" title=\"Type-1虚拟机\"></a>Type-1虚拟机</h6><p>在数据中心里面用的虚拟机，我们通常叫作Type-1型的虚拟机。客户机的指令交给虚拟机监视器之后呢，不再需要通过宿主机的操作系统，才能调用硬件，而是可以直接由虚拟机监视器去调用硬件。</p>\n<p>在Type-1型的虚拟机里，我们的虚拟机监视器其实并不是一个操作系统之上的应用层程序，而是一个嵌入在操作系统内核里面的一部分。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705165808.png\"></p>\n<h6 id=\"Docker\"><a href=\"#Docker\" class=\"headerlink\" title=\"Docker\"></a>Docker</h6><p>在我们实际的物理机上，我们可能同时运行了多个的虚拟机，而这每一个虚拟机，都运行了一个属于自己的单独的操作系统。多运行一个操作系统，意味着我们要多消耗一些资源在CPU、内存乃至磁盘空间上。</p>\n<p>在服务器领域，我们开发的程序都是跑在Linux上的。其实我们并不需要一个独立的操作系统，只要一个能够进行资源和环境隔离的“独立空间”就好了。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705165833.png\"></p>\n<p>通过Docker，我们不再需要在操作系统上再跑一个操作系统，而只需要通过容器编排工具，比如Kubernetes或者Docker Swarm，能够进行各个应用之间的环境和资源隔离就好了。</p>\n<h4 id=\"存储器\"><a href=\"#存储器\" class=\"headerlink\" title=\"存储器\"></a>存储器</h4><h5 id=\"SRAM\"><a href=\"#SRAM\" class=\"headerlink\" title=\"SRAM\"></a>SRAM</h5><p>SRAM（Static Random-Access Memory，静态随机存取存储器），被用在CPU Cache中。</p>\n<p>SRAM之所以被称为“静态”存储器，是因为只要处在通电状态，里面的数据就可以保持存在。而一旦断电，里面的数据就会丢失了。在SRAM里面，一个比特的数据，需要6～8个晶体管。所以SRAM的存储密度不高。同样的物理空间下，能够存储的数据有限。不过，因为SRAM的电路简单，所以访问速度非常快。</p>\n<p>在CPU里，通常会有L1、L2、L3这样三层高速缓存。每个CPU核心都有一块属于自己的L1高速缓存。</p>\n<p>L2的Cache同样是每个CPU核心都有的，不过它往往不在CPU核心的内部。所以，L2 Cache的访问速度会比L1稍微慢一些。</p>\n<p>L3 Cache，则通常是多个CPU核心共用的，尺寸会更大一些，访问速度自然也就更慢一些。</p>\n<h5 id=\"DRAM\"><a href=\"#DRAM\" class=\"headerlink\" title=\"DRAM\"></a>DRAM</h5><p>内存用的芯片是一种叫作DRAM（Dynamic Random Access Memory，动态随机存取存储器）的芯片，比起SRAM来说，它的密度更高，有更大的容量，而且它也比SRAM芯片便宜不少。</p>\n<p>DRAM被称为“动态”存储器，是因为DRAM需要靠不断地“刷新”，才能保持数据被存储起来。DRAM的一个比特，只需要一个晶体管和一个电容就能存储。所以，DRAM在同样的物理空间下，能够存储的数据也就更多，也就是存储的“密度”更大。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705165846.png\"></p>\n<h5 id=\"CPU-Cache\"><a href=\"#CPU-Cache\" class=\"headerlink\" title=\"CPU Cache\"></a>CPU Cache</h5><p>目前看来，一次内存的访问，大约需要120个CPU Cycle，这也意味着，在今天，CPU和内存的访问速度已经有了120倍的差距。</p>\n<p>为了弥补两者之间的性能差异，我们能真实地把CPU的性能提升用起来，而不是让它在那儿空转，我们在现代CPU中引入了高速缓存。</p>\n<p>CPU从内存中读取数据到CPU Cache的过程中，是一小块一小块来读取数据的，而不是按照单个数组元素来读取数据的。这样一小块一小块的数据，在CPU Cache里面，我们把它叫作Cache Line（缓存块）。</p>\n<p>在我们日常使用的Intel服务器或者PC里，Cache Line的大小通常是64字节。</p>\n<h5 id=\"直接映射Cache（Direct-Mapped-Cache）\"><a href=\"#直接映射Cache（Direct-Mapped-Cache）\" class=\"headerlink\" title=\"直接映射Cache（Direct Mapped Cache）\"></a>直接映射Cache（Direct Mapped Cache）</h5><p>对于读取内存中的数据，我们首先拿到的是数据所在的内存块（Block）的地址。而直接映射Cache采用的策略，就是确保任何一个内存块的地址，始终映射到一个固定的CPU Cache地址（Cache Line）。而这个映射关系，通常用mod运算（求余运算）来实现。</p>\n<p>比如说，我们的主内存被分成0～31号这样32个块。我们一共有8个缓存块。用户想要访问第21号内存块。如果21号内存块内容在缓存块中的话，它一定在5号缓存块（21 mod 8 &#x3D; 5）中。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705165857.png\"></p>\n<p>在对应的缓存块中，我们会存储一个组标记（Tag）。这个组标记会记录，当前缓存块内存储的数据对应的内存块，而缓存块本身的地址表示访问地址的低N位。</p>\n<p>除了组标记信息之外，缓存块中还有两个数据。一个自然是从主内存中加载来的实际存放的数据，另一个是有效位（valid bit）。啥是有效位呢？它其实就是用来标记，对应的缓存块中的数据是否是有效的，确保不是机器刚刚启动时候的空数据。如果有效位是0，无论其中的组标记和Cache Line里的数据内容是什么，CPU都不会管这些数据，而要直接访问内存，重新加载数据。</p>\n<p>CPU在读取数据的时候，并不是要读取一整个Block，而是读取一个他需要的整数。这样的数据，我们叫作CPU里的一个字（Word）。具体是哪个字，就用这个字在整个Block里面的位置来决定。这个位置，我们叫作偏移量（Offset）。</p>\n<p><em><strong>一个内存的访问地址，最终包括高位代表的组标记、低位代表的索引，以及在对应的Data Block中定位对应字的位置偏移量。</strong></em></p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705165917.png\"></p>\n<p>如果内存中的数据已经在CPU Cache里了，那一个内存地址的访问，就会经历这样4个步骤：</p>\n<p>1、根据内存地址的低位，计算在Cache中的索引</p>\n<p>2、判断有效位，确认Cache中的数据是有效的；</p>\n<p>3、对比内存访问地址的高位，和Cache中的组标记，确认Cache中的数据就是我们要访问的内存数据，从Cache Line中读取到对应的数据块（Data Block）；</p>\n<p>4、根据内存地址的Offset位，从Data Block中，读取希望读取到的字。</p>\n<h5 id=\"CPU高速缓存的写入\"><a href=\"#CPU高速缓存的写入\" class=\"headerlink\" title=\"CPU高速缓存的写入\"></a>CPU高速缓存的写入</h5><p>每一个CPU核里面，都有独立属于自己的L1、L2的Cache，然后再有多个CPU核共用的L3的Cache、主内存。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705165928.png\"></p>\n<h5 id=\"写直达（Write-Through）\"><a href=\"#写直达（Write-Through）\" class=\"headerlink\" title=\"写直达（Write-Through）\"></a>写直达（Write-Through）</h5><p>最简单的一种写入策略，叫作写直达（Write-Through）。在这个策略里，每一次数据都要写入到主内存里面。在写直达的策略里面，写入前，我们会先去判断数据是否已经在Cache里面了。如果数据已经在Cache里面了，我们先把数据写入更新到Cache里面，再写入到主内存里面；如果数据不在Cache里，我们就只更新主内存。</p>\n<p>这个策略很慢。无论数据是不是在Cache里面，我们都需要把数据写到主内存里面。</p>\n<p>#####写回（Write-Back）</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705170106.png\"></p>\n<p>如果发现我们要写入的数据，就在CPU Cache里面，那么我们就只是更新CPU Cache里面的数据。同时，我们会标记CPU Cache里的这个Block是脏（Dirty）的。所谓脏的，就是指这个时候，我们的CPU Cache里面的这个Block的数据，和主内存是不一致的。</p>\n<p>如果我们发现，我们要写入的数据所对应的Cache Block里，放的是别的内存地址的数据，那么我们就要看一看，那个Cache Block里面的数据有没有被标记成脏的。如果是脏的话，我们要先把这个Cache Block里面的数据，写入到主内存里面。</p>\n<p>然后，再把当前要写入的数据，写入到Cache里，同时把Cache Block标记成脏的。如果Block里面的数据没有被标记成脏的，那么我们直接把数据写入到Cache里面，然后再把Cache Block标记成脏的就好了。</p>\n<h5 id=\"MESI协议：让多核CPU的高速缓存保持一致\"><a href=\"#MESI协议：让多核CPU的高速缓存保持一致\" class=\"headerlink\" title=\"MESI协议：让多核CPU的高速缓存保持一致#\"></a>MESI协议：让多核CPU的高速缓存保持一致#</h5><p>MESI协议，是一种叫作写失效（Write Invalidate）的协议。在写失效协议里，只有一个CPU核心负责写入数据，其他的核心，只是同步读取到这个写入。在这个CPU核心写入Cache之后，它会去广播一个“失效”请求告诉所有其他的CPU核心。其他的CPU核心，只是去判断自己是否也有一个“失效”版本的Cache Block，然后把这个也标记成失效的就好了。</p>\n<p>MESI协议对Cache Line的四个不同的标记，分别是：</p>\n<ul>\n<li>M：代表已修改（Modified）</li>\n<li>E：代表独占（Exclusive）</li>\n<li>S：代表共享（Shared）</li>\n<li>I：代表已失效（Invalidated）</li>\n</ul>\n<p>所谓的“已修改”，就是我们上一讲所说的“脏”的Cache Block。Cache Block里面的内容我们已经更新过了，但是还没有写回到主内存里面。</p>\n<p>所谓的“已失效“，自然是这个Cache Block里面的数据已经失效了，我们不可以相信这个Cache Block里面的数据。</p>\n<p>在独占状态下，对应的Cache Line只加载到了当前CPU核所拥有的Cache里。其他的CPU核，并没有加载对应的数据到自己的Cache里。这个时候，如果要向独占的Cache Block写入数据，我们可以自由地写入数据，而不需要告知其他CPU核。</p>\n<p>在独占状态下的数据，如果收到了一个来自于总线的读取对应缓存的请求，它就会变成共享状态。这个共享状态是因为，这个时候，另外一个CPU核心，也把对应的Cache Block，从内存里面加载到了自己的Cache里来。</p>\n<p>而<em><strong>在共享状态下</strong></em>，因为同样的数据在多个CPU核心的Cache里都有。所以，当我们想要更新Cache里面的数据的时候，<em><strong>不能直接修改</strong></em>，而是要先向所有的其他CPU核心广播一个请求，要求先把其他CPU核心里面的Cache，都变成无效的状态，然后再更新当前Cache里面的数据。这个广播操作，一般叫作RFO（Request For Ownership），也就是获取当前对应Cache Block数据的所有权。</p>\n<h4 id=\"内存\"><a href=\"#内存\" class=\"headerlink\" title=\"内存\"></a>内存</h4><p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705170259.png\"></p>\n<p>内存是五大组成部分里面的存储器，我们的指令和数据，都需要先加载到内存里面，才会被CPU拿去执行。</p>\n<p>我们的内存需要被分成固定大小的页（Page），然后再通过虚拟内存地址（Virtual Address）到物理内存地址（Physical Address）的地址转换（Address Translation），才能到达实际存放数据的物理内存位置。而我们的程序看到的内存地址，都是虚拟内存地址。</p>\n<h5 id=\"页表\"><a href=\"#页表\" class=\"headerlink\" title=\"页表\"></a>页表</h5><p>想要把虚拟内存地址，映射到物理内存地址，最直观的办法，就是来建一张映射表。虚拟内存里面的页，到物理内存里面的页的一一映射。这个映射表，在计算机里面，就叫作页表（Page Table）。</p>\n<p>页表这个地址转换的办法，会把一个内存地址分成页号（Directory）和偏移量（Offset）两个部分。</p>\n<p>对于一个内存地址转换，其实就是这样三个步骤：</p>\n<p>1、把虚拟内存地址，切分成页号和偏移量的组合</p>\n<p>2、从页表里面，查询出虚拟页号，对应的物理页号</p>\n<p>3、直接拿物理页号，加上前面的偏移量，就得到了物理内存地址</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705170314.png\"></p>\n<h5 id=\"多级页表（Multi-Level-Page-Table）\"><a href=\"#多级页表（Multi-Level-Page-Table）\" class=\"headerlink\" title=\"多级页表（Multi-Level Page Table）\"></a>多级页表（Multi-Level Page Table）</h5><p>大部分进程所占用的内存是有限的，需要的页也自然是很有限的。我们只需要去存那些用到的页之间的映射关系就好了。</p>\n<p>在整个进程的内存地址空间，通常是“两头实、中间空”。在程序运行的时候，内存地址从顶部往下，不断分配占用的栈的空间。而堆的空间，内存地址则是从底部往上，是不断分配占用的。</p>\n<p>所以，在一个实际的程序进程里面，虚拟内存占用的地址空间，通常是两段连续的空间。</p>\n<p>我们以一个4级的多级页表为例，来看一下。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705170340.png\"></p>\n<p>对应的，一个进程会有一个4级页表。我们先通过4级页表索引，找到4级页表里面对应的条目（Entry）。这个条目里存放的是一张3级页表所在的位置。4级页面里面的每一个条目，都对应着一张3级页表，所以我们可能有多张3级页表。</p>\n<p>找到对应这张3级页表之后，我们用3级索引去找到对应的3级索引的条目。3级索引的条目再会指向一个2级页表。同样的，2级页表里我们可以用2级索引指向一个1级页表。</p>\n<p>而最后一层的1级页表里面的条目，对应的数据内容就是物理页号了。在拿到了物理页号之后，我们同样可以用“页号+偏移量”的方式，来获取最终的物理内存地址。</p>\n<h5 id=\"TLB加速地址转换\"><a href=\"#TLB加速地址转换\" class=\"headerlink\" title=\"TLB加速地址转换\"></a>TLB加速地址转换</h5><p>程序里面的每一个进程，都有一个属于自己的虚拟内存地址空间。我们可以通过地址转换来获得最终的实际物理地址。我们每一个指令都存放在内存里面，每一条数据都存放在内存里面。<br>“地址转换”是一个非常高频的动作，“地址转换”的性能就变得至关重要了。</p>\n<p>多级页表让原本只需要访问一次内存的操作，变成了需要访问4次内存，才能找到物理页号。<br>程序所需要使用的指令，都顺序存放在虚拟内存里面。我们执行的指令，也是一条条顺序执行下去的。</p>\n<p>于是，计算机工程师们专门在CPU里放了一块缓存芯片。这块缓存芯片我们称之为TLB，全称是地址<em><strong>变换高速缓冲</strong></em>（Translation-Lookaside Buffer）。这块缓存存放了之前已经进行过地址转换的查询结果。这样，当同样的虚拟地址需要进行地址转换的时候，我们可以直接在TLB里面查询结果，而不需要多次访问内存来完成一次转换。</p>\n<p>TLB和我们前面讲的CPU的高速缓存类似，可以分成指令的TLB和数据的TLB，也就是ITLB和DTLB。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705170433.png\"></p>\n<p>为了性能，我们整个内存转换过程也要由硬件来执行。在CPU芯片里面，我们封装了内存管理单元（MMU，Memory Management Unit）芯片，用来完成地址转换。和TLB的访问和交互，都是由这个MMU控制的。</p>\n<h4 id=\"I-x2F-O\"><a href=\"#I-x2F-O\" class=\"headerlink\" title=\"I&#x2F;O\"></a>I&#x2F;O</h4><p>我们先来看一个固态硬盘的Benchmark图：</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705170459.png\"></p>\n<p>“4K”的指标就是我们的程序，去随机读取磁盘上某一个4KB大小的数据，一秒之内可以读取到多少数据。</p>\n<p>我们拿这个40MB&#x2F;s和一次读取4KB的数据算一下。 40MB &#x2F; 4KB &#x3D; 10,000 也就是说，一秒之内，这块SSD硬盘可以随机读取1万次的4KB的数据。如果是写入的话呢，会更多一些，90MB &#x2F;4KB 差不多是2万多次。</p>\n<p>这个每秒读写的次数，我们称之为IOPS，也就是每秒输入输出操作的次数。<br>DTR（Data Transfer Rate，数据传输率）</p>\n<p>我们在实际的应用开发当中，对于数据的访问，更多的是随机读写，而不是顺序读写。</p>\n<h5 id=\"诊断-I-x2F-O瓶颈\"><a href=\"#诊断-I-x2F-O瓶颈\" class=\"headerlink\" title=\"诊断 I&#x2F;O瓶颈\"></a>诊断 I&#x2F;O瓶颈</h5><p>首先看一下CPU有没有在等待io操作。</p>\n<pre class=\"line-numbers language-#\" data-language=\"#\"><div class=\"caption\"><span>top</span></div><code class=\"language-#\">\n\ntop - 06:26:30 up 4 days, 53 min,  1 user,  load average: 0.79, 0.69, 0.65\nTasks: 204 total,   1 running, 203 sleeping,   0 stopped,   0 zombie\n%Cpu(s): 20.0 us,  1.7 sy,  0.0 ni, 77.7 id,  0.0 wa,  0.0 hi,  0.7 si,  0.0 st\nKiB Mem:   7679792 total,  6646248 used,  1033544 free,   251688 buffers\nKiB Swap:        0 total,        0 used,        0 free.  4115536 cached Mem<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>wa的指标，这个指标就代表着iowait，也就是CPU等待IO完成操作花费的时间占CPU的百分比。</p>\n<p>如果iowait很大，那么就可以去看看实际的I&#x2F;O操作情况是什么样的。使用iostat，就能够看到实际的硬盘读写情况。</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">$ iostat\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n17.02    0.01    2.18    0.04    0.00   80.76\nDevice:            tps    kB_read&#x2F;s    kB_wrtn&#x2F;s    kB_read    kB_wrtn\nsda               1.81         2.02        30.87     706768   10777408<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>tps指标，其实就对应着我们上面所说的硬盘的IOPS性能。而kB_read&#x2F;s和kB_wrtn&#x2F;s指标，就对应着我们的数据传输率的指标。</p>\n<p>使用iotop找出到底是哪一个进程是这些I&#x2F;O读写的来源。</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">$ iotop\n\nTotal DISK READ :       0.00 B&#x2F;s | Total DISK WRITE :      15.75 K&#x2F;s\nActual DISK READ:       0.00 B&#x2F;s | Actual DISK WRITE:      35.44 K&#x2F;s\nTID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO&gt;    COMMAND\n104 be&#x2F;3 root        0.00 B&#x2F;s    7.88 K&#x2F;s  0.00 %  0.18 % [jbd2&#x2F;sda1-8]\n383 be&#x2F;4 root        0.00 B&#x2F;s    3.94 K&#x2F;s  0.00 %  0.00 % rsyslogd -n [rs:main Q:Reg]\n1514 be&#x2F;4 www-data    0.00 B&#x2F;s    3.94 K&#x2F;s  0.00 %  0.00 % nginx: worker process<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n<h4 id=\"硬盘\"><a href=\"#硬盘\" class=\"headerlink\" title=\"硬盘\"></a>硬盘</h4><h5 id=\"机械硬盘\"><a href=\"#机械硬盘\" class=\"headerlink\" title=\"机械硬盘\"></a>机械硬盘</h5><p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705171106.png\"></p>\n<p>一块机械硬盘是由盘面、磁头和悬臂三个部件组成的。</p>\n<p>首先，自然是盘面（Disk Platter）。盘面其实就是我们实际存储数据的盘片。</p>\n<p>我们的硬盘有5400转的、7200转的，乃至10000转的。这个多少多少转，指的就是盘面中间电机控制的转轴的旋转速度，英文单位叫RPM，也就是每分钟的旋转圈数（Rotations Per Minute）。</p>\n<p>磁头：数据并不能直接从盘面传输到总线上，而是通过磁头，从盘面上读取到，然后再通过电路信号传输给控制电路、接口，再到总线上的。通常，我们的一个盘面上会有两个磁头，分别在盘面的正反面。</p>\n<p>悬臂链接在磁头上，并且在一定范围内会去把磁头定位到盘面的某个特定的磁道（Track）上。</p>\n<p>一个盘面通常是圆形的，由很多个同心圆组成，每一个同心圆都是一个磁道。每个磁道都有自己的一个编号。</p>\n<p>磁道，会分成一个一个扇区（Sector）。上下平行的一个一个盘面的相同扇区呢，我们叫作一个柱面（Cylinder）。</p>\n<p>读取数据，其实就是两个步骤。</p>\n<p>把盘面旋转到某一个位置。在这个位置上，我们的悬臂可以定位到整个盘面的某一个子区间。</p>\n<p>把我们的悬臂移动到特定磁道的特定扇区，也就在这个“几何扇区”里面，找到我们实际的扇区。找到之后，我们的磁头会落下，就可以读取到正对着扇区的数据。</p>\n<p>进行一次硬盘上的随机访问，需要的时间由两个部分组成。</p>\n<p>第一个部分，叫作平均延时（Average Latency）。这个时间，其实就是把我们的盘面旋转，把几何扇区对准悬臂位置的时间。这个时间很容易计算，它其实就和我们机械硬盘的转速相关。</p>\n<p>随机情况下，平均找到一个几何扇区，我们需要旋转半圈盘面。上面7200转的硬盘，那么一秒里面，就可以旋转240个半圈。那么，这个平均延时就是：1s &#x2F; 240 &#x3D; 4.17ms</p>\n<p>第二个部分，叫作平均寻道时间（Average Seek Time），也就是在盘面选转之后，我们的悬臂定位到扇区的的时间。我们现在用的HDD硬盘的平均寻道时间一般在4-10ms。</p>\n<h5 id=\"SSD硬盘\"><a href=\"#SSD硬盘\" class=\"headerlink\" title=\"SSD硬盘\"></a>SSD硬盘</h5><p>现在新的大容量SSD硬盘是由很多个裸片（Die）叠在一起的，就好像我们的机械硬盘把很多个盘面（Platter）叠放再一起一样，这样可以在同样的空间下放下更多的容量。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705171121.png\"></p>\n<p>一张裸片上可以放多个平面（Plane），一般一个平面上的存储容量大概在GB级别。一个平面上面，会划分成很多个块（Block），一般一个块（Block）的存储大小， 通常几百KB到几MB大小。一个块里面，还会区分很多个页（Page），就和我们内存里面的页一样，一个页的大小通常是4KB。</p>\n<p>对于SSD硬盘来说，数据的写入叫作Program。写入不能像机械硬盘一样，通过覆写（Overwrite）来进行的，而是要先去擦除（Erase），然后再写入。</p>\n<p>SSD的读取和写入的基本单位，不是一个比特（bit）或者一个字节（byte），而是一个页（Page）。SSD的擦除单位必须按照块来擦除。</p>\n<p>SSD的使用寿命，其实是每一个块（Block）的擦除的次数。</p>\n<p>SLC的芯片，可以擦除的次数大概在10万次，MLC就在1万次左右，而TLC和QLC就只在几千次了。</p>\n<h5 id=\"SSD读写的生命周期\"><a href=\"#SSD读写的生命周期\" class=\"headerlink\" title=\"SSD读写的生命周期\"></a>SSD读写的生命周期</h5><p>白色代表这个页从来没有写入过数据，绿色代表里面写入的是有效的数据，红色代表里面的数据，在我们的操作系统看来已经是删除的了。</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705171217.png\"></p>\n<p>一开始，所有块的每一个页都是白色的。随着我们开始往里面写数据，里面的有些页就变成了绿色。</p>\n<p>然后，因为我们删除了硬盘上的一些文件，所以有些页变成了红色。但是这些红色的页，并不能再次写入数据。因为SSD硬盘不能单独擦除一个页，必须一次性擦除整个块，所以新的数据，我们只能往后面的白色的页里面写。这些散落在各个绿色空间里面的红色空洞，就好像硬盘碎片。</p>\n<p>如果有哪一个块的数据一次性全部被标红了，那我们就可以把整个块进行擦除。它就又会变成白色，可以重新一页一页往里面写数据。</p>\n<p>在快要没有白色的空页去写入数据的时候，SSD会做一次类似于Windows里面“磁盘碎片整理”或者Java里面的“内存垃圾回收”工作。找一个红色空洞最多的块，把里面的绿色数据，挪到另一个块里面去，然后把整个块擦除，变成白色，可以重新写入数据。</p>\n<h4 id=\"DMA\"><a href=\"#DMA\" class=\"headerlink\" title=\"DMA\"></a>DMA</h4><h5 id=\"为什么要发明DMA技术？\"><a href=\"#为什么要发明DMA技术？\" class=\"headerlink\" title=\"为什么要发明DMA技术？\"></a>为什么要发明DMA技术？</h5><p>就目前而言I&#x2F;O速度如何提升，比起CPU，总还是太慢。如果我们对于I&#x2F;O的操作，都是由CPU发出对应的指令，然后等待I&#x2F;O设备完成操作之后返回，那CPU有大量的时间其实都是在等待I&#x2F;O设备完成操作。</p>\n<p>但是，这个CPU的等待，在很多时候，其实并没有太多的实际意义。我们对于I&#x2F;O设备的大量操作，其实都只是把内存里面的数据，传输到I&#x2F;O设备而已。</p>\n<p>因此，计算机工程师们，就发明了DMA技术，也就是直接内存访问（Direct Memory Access）技术，来减少CPU等待的时间。</p>\n<h5 id=\"DMA有什么用？\"><a href=\"#DMA有什么用？\" class=\"headerlink\" title=\"DMA有什么用？\"></a>DMA有什么用？</h5><p>本质上，DMA技术就是我们在主板上放一块独立的芯片。在进行内存和I&#x2F;O设备的数据传输的时候，我们不再通过CPU来控制数据传输，而直接通过DMA控制器（DMA Controller，简称DMAC）。</p>\n<p>当传输大量数据的时候，DMAC可以等数据到齐了，再发送信号，给到CPU去处理，而不是让CPU在那里忙等待。</p>\n<h5 id=\"DMAC是怎么控制数据传输的？\"><a href=\"#DMAC是怎么控制数据传输的？\" class=\"headerlink\" title=\"DMAC是怎么控制数据传输的？\"></a>DMAC是怎么控制数据传输的？</h5><p>DMAC其实也是一个特殊的I&#x2F;O设备，它和CPU以及其他I&#x2F;O设备一样，通过连接到总线来进行实际的数据传输。总线上的设备呢，其实有两种类型。一种我们称之为主设备（Master），另外一种，我们称之为从设备（Slave）。</p>\n<p>想要主动发起数据传输，必须要是一个主设备才可以，CPU就是主设备。而我们从设备（比如硬盘）只能接受数据传输。</p>\n<p>DMAC它既是一个主设备，又是一个从设备。对于CPU来说，它是一个从设备；对于硬盘这样的IO设备来说呢，它又变成了一个主设备。</p>\n<p>我们下面看一张图：</p>\n<p><img src=\"https://raw.githubusercontent.com/effygao/picture/master/img/20220705171250.png\"></p>\n<p>1、首先，CPU还是作为一个主设备，向DMAC设备发起请求。这个请求，其实就是在DMAC里面修改配置寄存器。</p>\n<p>2、CPU修改DMAC的配置的时候，会告诉DMAC这样几个信息：</p>\n<ul>\n<li>首先是源地址的初始值以及传输时候的地址增减方式。</li>\n</ul>\n<p>所谓源地址，就是数据要从哪里传输过来。如果我们要从内存里面写入数据到硬盘上，那么就是要读取的数据在内存里面的地址。</p>\n<ul>\n<li><p>其次是目标地址初始值和传输时候的地址增减方式。</p>\n</li>\n<li><p>第三个是要传输的数据长度</p>\n</li>\n</ul>\n<p>3、设置完这些信息之后，DMAC就会变成一个空闲的状态（Idle）。</p>\n<p>4、如果我们要从硬盘上往内存里面加载数据，这个时候，硬盘就会向DMAC发起一个数据传输请求。这个请求并不是通过总线，而是通过一个额外的连线。</p>\n<p>5、然后，我们的DMAC需要再通过一个额外的连线响应这个申请。</p>\n<p>6、于是，DMAC这个芯片，就向硬盘的接口发起要总线读的传输请求。数据就从硬盘里面，读到了DMAC的控制器里面。</p>\n<p>7、然后，DMAC再向我们的内存发起总线写的数据传输请求，把数据写入到内存里面。</p>\n<p>8、DMAC会反复进行上面第6、7步的操作，直到DMAC的寄存器里面设置的数据长度传输完成。</p>\n<p>9、数据传输完成之后，DMAC重新回到第3步的空闲状态。</p>\n<h4 id=\"结束语\"><a href=\"#结束语\" class=\"headerlink\" title=\"结束语\"></a>结束语</h4><p>以上，是我在大二期间《计算机组成原理》课程的全部笔记，全部由个人独自整理收集。</p>\n","text":"CPU性能响应时间：指的就是，我们执行一个程序，到底需要花多少时间。花的时间越少，自然性能就越好。 吞吐率：在一定的时间范围内，到底能处理多少事情。这里的“事情”，在计算机里就是处理的数据或者执行的程序指令。 我们一般把性能，定义成响应时间的倒数，也就是： 性能 &#x3D; 1...","link":"","photos":[],"count_time":{"symbolsCount":"28k","symbolsTime":"26 mins."},"categories":[],"tags":[{"name":"Education","slug":"Education","count":1,"path":"api/tags/Education.json"},{"name":"ComputerScience","slug":"ComputerScience","count":1,"path":"api/tags/ComputerScience.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#CPU%E6%80%A7%E8%83%BD\"><span class=\"toc-text\">CPU性能</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%A8%8B%E5%BA%8F%E8%BF%90%E8%A1%8C%E7%9A%84%E6%97%B6%E9%97%B4\"><span class=\"toc-text\">程序运行的时间</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%B9%B6%E8%A1%8C%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">并行优化</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E4%BB%8E%E7%BC%96%E8%AF%91%E5%88%B0%E6%B1%87%E7%BC%96%EF%BC%8C%E4%BB%A3%E7%A0%81%E6%80%8E%E4%B9%88%E5%8F%98%E6%88%90%E6%9C%BA%E5%99%A8%E7%A0%81%EF%BC%9F\"><span class=\"toc-text\">从编译到汇编，代码怎么变成机器码？</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%8C%87%E4%BB%A4%E6%98%AF%E5%A6%82%E4%BD%95%E8%A2%AB%E6%89%A7%E8%A1%8C%E7%9A%84\"><span class=\"toc-text\">指令是如何被执行的</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%89%A7%E8%A1%8C%E5%92%8C%E8%B7%B3%E8%BD%AC\"><span class=\"toc-text\">程序的执行和跳转</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8\"><span class=\"toc-text\">函数调用</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%8B%86%E8%A7%A3%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C\"><span class=\"toc-text\">拆解程序执行</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E9%9D%99%E6%80%81%E9%93%BE%E6%8E%A5\"><span class=\"toc-text\">静态链接</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5\"><span class=\"toc-text\">动态链接</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E8%A3%85%E8%BD%BD%E7%A8%8B%E5%BA%8F\"><span class=\"toc-text\">装载程序</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%86%85%E5%AD%98%E5%88%86%E9%A1%B5\"><span class=\"toc-text\">内存分页</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%B5%AE%E7%82%B9%E6%95%B0%E5%92%8C%E5%AE%9A%E7%82%B9%E6%95%B0\"><span class=\"toc-text\">浮点数和定点数</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%AE%9A%E7%82%B9%E6%95%B0\"><span class=\"toc-text\">定点数</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%B5%AE%E7%82%B9%E6%95%B0\"><span class=\"toc-text\">浮点数</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E5%8D%95%E7%B2%BE%E5%BA%A6\"><span class=\"toc-text\">单精度</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E7%89%B9%E6%AE%8A%E5%80%BC%E7%9A%84%E8%A1%A8%E7%A4%BA\"><span class=\"toc-text\">特殊值的表示</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E6%B5%AE%E7%82%B9%E6%95%B0%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E8%BD%AC%E5%8C%96\"><span class=\"toc-text\">浮点数的二进制转化</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E6%B5%AE%E7%82%B9%E6%95%B0%E7%9A%84%E5%8A%A0%E6%B3%95%E5%92%8C%E7%B2%BE%E5%BA%A6%E6%8D%9F%E5%A4%B1\"><span class=\"toc-text\">浮点数的加法和精度损失</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%8C%87%E4%BB%A4%E5%91%A8%E6%9C%9F%EF%BC%88Instruction-Cycle%EF%BC%89\"><span class=\"toc-text\">指令周期（Instruction Cycle）</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%97%B6%E5%BA%8F%E9%80%BB%E8%BE%91%E7%94%B5%E8%B7%AF\"><span class=\"toc-text\">时序逻辑电路</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#PC%E5%AF%84%E5%AD%98%E5%99%A8\"><span class=\"toc-text\">PC寄存器</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84CPU%E6%B5%81%E7%A8%8B\"><span class=\"toc-text\">最简单的CPU流程</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%8C%87%E4%BB%A4%E6%B5%81%E6%B0%B4%E7%BA%BF\"><span class=\"toc-text\">指令流水线</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%B5%81%E6%B0%B4%E7%BA%BF%E8%AE%BE%E8%AE%A1CPU%E7%9A%84%E9%A3%8E%E9%99%A9\"><span class=\"toc-text\">流水线设计CPU的风险</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E7%BB%93%E6%9E%84%E5%86%92%E9%99%A9\"><span class=\"toc-text\">结构冒险</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E5%86%92%E9%99%A9\"><span class=\"toc-text\">数据冒险</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E6%93%8D%E4%BD%9C%E6%95%B0%E5%89%8D%E6%8E%A8\"><span class=\"toc-text\">操作数前推</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#CPU%E6%8C%87%E4%BB%A4%E4%B9%B1%E5%BA%8F%E6%89%A7%E8%A1%8C\"><span class=\"toc-text\">CPU指令乱序执行</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E8%B6%85%E7%BA%BF%E7%A8%8B\"><span class=\"toc-text\">超线程</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#SIMD%E5%8A%A0%E9%80%9F%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95\"><span class=\"toc-text\">SIMD加速矩阵乘法</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E5%BC%82%E5%B8%B8%E5%92%8C%E4%B8%AD%E6%96%AD\"><span class=\"toc-text\">异常和中断</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#%E5%BC%82%E5%B8%B8\"><span class=\"toc-text\">异常</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#%E5%BC%82%E5%B8%B8%E7%9A%84%E5%88%86%E7%B1%BB\"><span class=\"toc-text\">异常的分类</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#%E5%BC%82%E5%B8%B8%E7%9A%84%E5%A4%84%E7%90%86%EF%BC%9A%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2\"><span class=\"toc-text\">异常的处理：上下文切换</span></a></li></ol></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%8A%80%E6%9C%AF\"><span class=\"toc-text\">虚拟机技术</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#%E8%A7%A3%E9%87%8A%E5%9E%8B%E8%99%9A%E6%8B%9F%E6%9C%BA\"><span class=\"toc-text\">解释型虚拟机</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#Type-1%E5%92%8CType-2%E8%99%9A%E6%8B%9F%E6%9C%BA\"><span class=\"toc-text\">Type-1和Type-2虚拟机</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#Type-2%E8%99%9A%E6%8B%9F%E6%9C%BA\"><span class=\"toc-text\">Type-2虚拟机</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#Type-1%E8%99%9A%E6%8B%9F%E6%9C%BA\"><span class=\"toc-text\">Type-1虚拟机</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#Docker\"><span class=\"toc-text\">Docker</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%AD%98%E5%82%A8%E5%99%A8\"><span class=\"toc-text\">存储器</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#SRAM\"><span class=\"toc-text\">SRAM</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#DRAM\"><span class=\"toc-text\">DRAM</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#CPU-Cache\"><span class=\"toc-text\">CPU Cache</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E7%9B%B4%E6%8E%A5%E6%98%A0%E5%B0%84Cache%EF%BC%88Direct-Mapped-Cache%EF%BC%89\"><span class=\"toc-text\">直接映射Cache（Direct Mapped Cache）</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#CPU%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98%E7%9A%84%E5%86%99%E5%85%A5\"><span class=\"toc-text\">CPU高速缓存的写入</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E5%86%99%E7%9B%B4%E8%BE%BE%EF%BC%88Write-Through%EF%BC%89\"><span class=\"toc-text\">写直达（Write-Through）</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#MESI%E5%8D%8F%E8%AE%AE%EF%BC%9A%E8%AE%A9%E5%A4%9A%E6%A0%B8CPU%E7%9A%84%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98%E4%BF%9D%E6%8C%81%E4%B8%80%E8%87%B4\"><span class=\"toc-text\">MESI协议：让多核CPU的高速缓存保持一致#</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%86%85%E5%AD%98\"><span class=\"toc-text\">内存</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E9%A1%B5%E8%A1%A8\"><span class=\"toc-text\">页表</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E5%A4%9A%E7%BA%A7%E9%A1%B5%E8%A1%A8%EF%BC%88Multi-Level-Page-Table%EF%BC%89\"><span class=\"toc-text\">多级页表（Multi-Level Page Table）</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#TLB%E5%8A%A0%E9%80%9F%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2\"><span class=\"toc-text\">TLB加速地址转换</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#I-x2F-O\"><span class=\"toc-text\">I&#x2F;O</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E8%AF%8A%E6%96%AD-I-x2F-O%E7%93%B6%E9%A2%88\"><span class=\"toc-text\">诊断 I&#x2F;O瓶颈</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%A1%AC%E7%9B%98\"><span class=\"toc-text\">硬盘</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E6%9C%BA%E6%A2%B0%E7%A1%AC%E7%9B%98\"><span class=\"toc-text\">机械硬盘</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#SSD%E7%A1%AC%E7%9B%98\"><span class=\"toc-text\">SSD硬盘</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#SSD%E8%AF%BB%E5%86%99%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F\"><span class=\"toc-text\">SSD读写的生命周期</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#DMA\"><span class=\"toc-text\">DMA</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%8F%91%E6%98%8EDMA%E6%8A%80%E6%9C%AF%EF%BC%9F\"><span class=\"toc-text\">为什么要发明DMA技术？</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#DMA%E6%9C%89%E4%BB%80%E4%B9%88%E7%94%A8%EF%BC%9F\"><span class=\"toc-text\">DMA有什么用？</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#DMAC%E6%98%AF%E6%80%8E%E4%B9%88%E6%8E%A7%E5%88%B6%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E7%9A%84%EF%BC%9F\"><span class=\"toc-text\">DMAC是怎么控制数据传输的？</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%BB%93%E6%9D%9F%E8%AF%AD\"><span class=\"toc-text\">结束语</span></a></li></ol>","author":{"name":"网工混子","slug":"blog-author","avatar":"https://raw.githubusercontent.com/effygao/picture/master/img/IMG_2542.jpeg","link":"/","description":"如果没能一次成功，那就叫它1.0版吧 <br /> <br /> @ <b>公众号：知研武院（建设中）</b>","socials":{"github":"https://github.com/effygao","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/people/dreamland-81","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://live.bilibili.com/185871311"},"qq":{"icon":"/svg/qq.svg","link":"http://wpa.qq.com/msgrd?v=3&uin=1595291236&site=qq&menu=yes"},"netmusic":{"icon":"/svg/music.svg","link":"https://music.163.com/#/user/home?id=115346351"}}}},"mapped":true,"prev_post":{},"next_post":{}}